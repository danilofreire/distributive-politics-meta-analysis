---
title: |
       | Supplementary Materials for "The Effect of Legislature Size on Public Spending: A Meta-Analysis"
author:
- "Huzeyfe Alptekin[^alptekin]"
- "Danilo Freire[^freire]"
- "Umberto Mignozzetti[^mignozzetti]"
- "Catarina Roman[^roman]"
date: \today
fontfamily: libertine
fontawesome: yes
fontsize: 11pt
monospace-url: yes
spacing: double
papersize: a4paper
bibliography: references.bib
biblio-style: apalike
always_allow_html: true
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    number_sections: yes
    toc: true
    keep_tex: no
    template: template.latex
---

\appendix

[^alptekin]: Research Associate, Contemporary Brazilian History Research and Documentation Center, School of Social Sciences, Getulio Vargas Foundation, Brazil, <huzeyfealptekin@gmail.com>.

[^freire]: Independent Researcher, <danilofreire@gmail.com>, <http://danilofreire.github.io>. Corresponding author.

[^mignozzetti]: Visiting Assistant Professor, Quantitative Theory and Methods, Emory University, <umberto.mignozzetti@emory.edu>, <http://umbertomig.com>.

[^roman]: Research Associate, School of International Relations, Fundação Getulio Vargas, São Paulo, SP, Brazil, <catarinamroman@gmail.com>.

```{r, include=FALSE}
# Knitr options
knitr::opts_chunk$set(fig.pos = "H") # holds figure position
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
## Starting
set.seed(732578) # From random.org

# Required packages
pkgs <- c("tidyverse", "meta", "metafor",
          "readxl", "devtools", "data.table",
          "knitr", "gridGraphics", "gridExtra",
          "ggpubr", "kableExtra", "magick")

# Install if not already installed
install <- function(x) {
  if (x %in% rownames(installed.packages()) == FALSE)
    install.packages(x, dependencies = T,
                     repos = "http://cran.us.r-project.org")
}
lapply(pkgs, install)
devtools::install_github("isubirana/compareGroups")

# Load packages
lapply(pkgs, require, character.only = T)
library("compareGroups")

# Load datasets
load("../dataset/dataCoefs.RData")

# Build plot function for forest plots
build_forest <- function(mod, capt, lsize = 22, ttl = NULL) {
  # Build dataset for plot
  mod2 <- tibble(
    TE = mod$TE,
    seTE = mod$seTE,
    studlab = mod$studlab,
    lower = mod$lower,
    upper = mod$upper,
    group = "A") %>%
    bind_rows(.,
              aux = tibble(
                TE = c(mod$TE.random, NA),
                seTE = c(mod$seTE.random, NA),
                studlab = c("Overall Effect",
                            "Prediction Interval"),
                lower = c(mod$lower.random,
                          mod$lower.predict),
                upper = c(mod$upper.random,
                          mod$upper.predict),
                group = "B")) %>%
    group_by(studlab) %>%
    mutate(studlab2 = paste0(studlab, "_", 1:n())) %>%
    ungroup()

  # Graph limits
  limg <- max(abs(c(mod2$lower, mod2$upper)))

  # Build plot
  p <- mod2 %>%
    ggplot(aes(y = reorder(studlab2, TE),
               x = TE, xmin = lower, xmax = upper)) +
    geom_point(aes(color = group)) +
    geom_errorbarh(aes(color = group),
                   height = 0.1) +
    scale_color_manual(values = c("#000000", "#8b0000")) +
    scale_x_continuous(limits = c(-1.1 * limg, 1.1 * limg)) +
    scale_y_discrete(
      labels = function(x)
        str_replace(x, "_[0-9]*$", "")) +
    geom_vline(xintercept = 0,
               color = "#000000", linetype = "dashed") +
    labs(x = "",
         y = "") +
    facet_grid(group~., scales = "free", space = "free") +
    labs(caption = capt,
         title = ttl) +
    theme_minimal() %+replace%
    theme(strip.text.y = element_blank(),
          legend.position = "none",
          axis.text.y = element_text(size = .8 * lsize,
                                     hjust = 1),
          axis.text.x = element_text(size = .6 * lsize,
                                     hjust = 1.1),
          plot.caption = element_text(size = lsize),
          plot.title.position = "plot",
          plot.title = element_text(hjust = 0.5,
                                    face = "bold",
                                    margin = margin(0, 0, 10, 0)),
          panel.grid.major = element_blank())
  return(p)
}

# Build forest plot for heterogeneous analysis
# Build plot function for forest plots
build_forest_het <- function(mod, capt, lsize = 22, ttl = NULL, hetvar = NULL) {
  mod <- update(mod, byvar = hetvar, print.byvar = F)

  # Build dataset for plot
  mod2 <- tibble(
    byvar = mod$byvar,
    TE = mod$TE,
    seTE = mod$seTE,
    studlab = mod$studlab,
    lower = mod$lower,
    upper = mod$upper,
    group = "A") %>%
    arrange(byvar)
  auxmod <- tibble()
  for (i in rev(mod$bylevs)){
    auxmod <- rbind(auxmod, tibble(byvar = i,
                    TE = NA,
                    seTE = NA,
                    studlab = toupper(i),
                    lower = NA,
                    upper = NA,
                    group = "B"))
    auxmod <- rbind(auxmod,
                    filter(mod2, byvar==i) %>%
                      arrange(desc(TE)))
    auxmod <- rbind(auxmod, tibble(
      byvar = i,
      TE = mod$TE.random.w[which(mod$bylevs==i)],
      seTE = mod$seTE.random.w[which(mod$bylevs==i)],
      studlab = 'Subgroup Effect',
      lower = mod$lower.random.w[which(mod$bylevs==i)],
      upper = mod$upper.random.w[which(mod$bylevs==i)],
      group = "B"))
  }
  auxmod <- rbind(auxmod, tibble(
    byvar = NA,
    TE = c(mod$TE.random, NA),
    seTE = c(mod$seTE.random, NA),
    studlab = c("Overall Effect", "Prediction Interval"),
    lower = c(mod$lower.random, mod$lower.predict),
    upper = c(mod$upper.random, mod$upper.predict),
    group = "B"))
  mod2 <- data.frame(auxmod)
  mod2$byvar <- toupper(mod2$byvar)
  TEaux <- mod2$TE
  TEaux[mod2$studlab== 'Subgroup Effect'] = TEaux[mod2$studlab== 'Subgroup Effect'] - 100

  # Graph limits
  limg <- max(abs(c(mod2$lower, mod2$upper)))

  # Build plot
  p <- mod2 %>%
    ggplot(aes(y = reorder(studlab, TEaux),
               x = TE, xmin = lower, xmax = upper)) +
    geom_point(aes(color = group)) +
    geom_errorbarh(aes(color = group),
                   height = 0.1) +
    scale_color_manual(values = c("#000000", "#8b0000")) +
    scale_x_continuous(limits = c(-1.1 * limg, 1.1 * limg)) +
    scale_y_discrete(
      labels = function(x)
        str_replace(x, "_[0-9]*$", "")) +
    geom_vline(xintercept = 0,
               color = "#000000", linetype = "dashed") +
    labs(x = "",
         y = "") +
    facet_grid(byvar~., scales = "free", space = "free") +
    labs(caption = capt,
         title = ttl) +
    theme_minimal() %+replace%
    theme(strip.text.y = element_blank(),
          legend.position = "none",
          axis.text.y = element_text(size = .8 * lsize,
                                     hjust = 1),
          axis.text.x = element_text(size = .6 * lsize,
                                     hjust = 1.1),
          plot.caption = element_text(size = lsize),
          plot.title.position = "plot",
          plot.title = element_text(hjust = 0.5,
                                    face = "bold",
                                    margin = margin(0, 0, 10, 0)),
          panel.grid.major = element_blank())
  return(p)
}
```

# Search Criteria

The first step in our systematic review consisted in gathering a study sample. We started our data collection with a manual search based on a set of keywords we scouted from the distributive politics literature. This search produced a database with many entries that were unrelated to our subject of investigation. To reduce the number of false positives in our sample, we restricted our search to studies that cited Weingast, Shepsle and Johnsen's 1981 paper "The Political Economy of Benefits and Costs: A Neoclassical Approach to Distributive Politics", which is a seminal contribution in the field. Although \href{https://scholar.google.com/}{Google Scholar} reports the article has received \href{https://scholar.google.com/scholar?um=1&ie=UTF-8&lr&cites=13117579863846712459}{2,180} citations, our search resulted in 2,664 records on the 21^st^ of November 2019.

We webscraped three large academic databases: \href{https://scholar.google.com/}{Google Scholar} (n = 1001); \href{https://academic.microsoft.com/home}{Microsoft Academic} (n = 927); and \href{https://www.scopus.com/}{Scopus} (n = 736). The `R` script we wrote extracted the article title, abstract, authors, year, journal of publication, and database from which the record originated. Our code is available in section \ref{sub:scrap} below. We screened these results with an English language and article restriction, that is, we excluded all records written in other languages and all that were not academic papers, such as book chapters or doctoral theses. We set no restriction to unpublished articles.

# Article Selection

The selection process was conducted by two authors in three phases. In the first round, we excluded all titles that were clearly unrelated to our topic of interest. For instance, we curiously found articles about automobile motors amidst our sample. We consider this a preliminary step, since we were not able to eliminate a large number of entries. Then, we read all abstracts. We chose to maintain those which indicated that either government expenditure or legislative structures were the main subject of the paper. For instance, if the paper sought to identify variables that increased government size, it was maintained. Abstracts that indicated the paper discussed or estimated the impacts of representative institutions, elections, or chamber dynamics were also included. This allowed us to significantly reduce our sample to 376 records.

In the second phase, we assessed full texts. To remain in our sample, the paper should (i) conduct a quantitative analysis, (ii) report data on the number of legislators, and (iii) also include data on public expenditure. If the publication had all three, it was maintained. Disagreements in this phase were discussed among the authors, and a third investigator was consulted when needed.

The third phase consisted of filling out tables for each of the remaining 50 articles to systematically evaluate their eligibility. Since authors use different measures for government spending and the number of lower/upper house members, we extracted all coefficients that provided this information. We decided which variables to keep by following the current practices of the literature. In this phase, we also collected information on whether or not the paper had been published, and if it explicitly discussed the \textit{law of 1/n}. Upon choosing the variables, we excluded the non-conforming studies, arriving at our final sample of `r length(unique(dat$authoryear))` articles.

## Exclusion Analysis

We selected the final pool of articles based on two criteria regarding their reported coefficients:

1. Matched treatment variable:
  + *N*: Number Legislators in the Lower House
  + *logN*: Log Number Legislators in the Lower House
  + *K*: Number Legislators in the Upper House

2. Matched outcome variable:
  + *ExpPC*: Expenditure Per Capita
  + *logExpPC*: Log Expenditure Per Capita
  + *PCTGDP*: Percent GDP Public Expenditure

## Flow Chart

The diagram below shows each step of our article selection process. We followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement to conduct our study\footnote{More information about the PRISMA statement is available at \url{http://www.prisma-statement.org}.}. The column to the right depicts the amount of articles excluded in each phase, and the one to the left shows the number of records evaluated.

\bigskip

```{tikz tikz-ex, echo=FALSE, cache=FALSE, eval=TRUE, engine.opts = list(template = "tikz2pdf.tex")}
\usetikzlibrary{shapes.arrows,arrows.meta,positioning,shapes.geometric}
  \begin{tikzpicture} [node distance = 2.7cm, xshift = 1.5]

  \footnotesize
  \linespread{1.0}

  \node (ID) [stage, rotate = 90, yshift = 2cm, xshift = 2.5cm] {\normalsize{Identification}};

  \node (SC) [stage, below of = ID, rotate = 90] {\normalsize{Screening}};

  \node (EL) [stage, below of = SC, rotate = 90] {\normalsize{Eligibility}};

  \node (INC) [stage2, below of = EL, rotate = 90, xshift = -1.2cm] {\normalsize{Included}};

  \node (id) [phase, right of = ID, xshift = 1cm] {Records identified through webscraping  \\ \textbf{(n = 2664)}};

  \node (1st) [exc, right of = id, xshift = 3cm] {Records in languages other than English, book chapters, doctoral theses, and duplicates excluded \\ \textbf{(n = 1220)}};

  \node (screen) [phase, below of = id] {Records screened \\ \textbf{(n = 1445)}};

  \node (2nd) [exc, right of = screen, xshift = 3cm] {Records excluded after reading title and abstract \\ \textbf{(n = 1069)}};

  \node (elig) [phase, below of = screen] {Full-text articles assessed for Eligibility \\ \textbf{(n = 376)}};

  \node (3rd) [exc, right of = elig, xshift = 3cm] {Non-quantitative studies or records using unrelated variables excluded \\ \textbf{(n = 329)}};

  \node (inc_1) [phase, below of = elig] {Preliminary included articles \\ \textbf{(n = 47)}};

  \node (4th) [exc, right of = inc_1, xshift = 3cm] {Articles excluded during analysis due to nonconforming variables \\ \textbf{(n = 18)}};

\node (inc_2) [phase, below of = inc_1] {Included articles \\ \textbf{(n = 29)}};
  \draw [arrow] (id) -- (1st);
  \draw [arrow] (id) -- (screen);
  \draw [arrow] (screen) -- (2nd);
  \draw [arrow] (screen) -- (elig);
  \draw [arrow] (elig) -- (3rd);
  \draw [arrow] (elig) -- (inc_1);
  \draw [arrow] (inc_1) -- (4th);
  \draw [arrow] (inc_1) -- (inc_2);

 \end{tikzpicture}
```

# Meta-Analysis Dataset

Our data are comprised of two datasets. The first dataset has the main coefficients reported in the studies. These data include only the most rigorous model from each paper, that is, those estimated with the largest sample size, most control variables, and fixed effects if the authors added them. If the article employed a regression discontinuity design, we chose the coefficient from the optimal bandwidth or from the intermediate one. This sample encompasses `r dim(dat)[1]` estimates, as `r as.numeric(table(table(dat$id))[2])` articles analysed two dependent or independent variables of interest. Our second sample, in contrast, contains all the `r dim(fulldat)[1]` effect sizes reported in the `r length(unique(dat$id))` papers.

In the main text, we focus on the results for our restricted sample as we consider them more robust, but the findings are very similar when we use the extended dataset. Below is the data extraction process for all relevant coefficients in the selected articles. Here we present the results of all tests performed in both reduced and full samples.

# Descriptive Statistics

In this section, we show the descriptive statistics for our sample. We focus on the following paper characteristics: study year, whether the paper has been published or not, the electoral system of the country discussed in the original study, the data aggregation level, as well as the distribution of the dependent and independent variables of interest. We also add a descriptive statistics table similar to the one in the main paper.

## Study Year

For study year, we have an average of `r round(mean(dat$year), 2)`, with standard deviation of `r round(sd(dat$year), 2)`. The oldest study included in the paper is from `r min(dat$year)`, while the most recent paper was written in `r max(dat$year)`. Therefore, we cover `r max(dat$year)-min(dat$year)` years of tests of the _law of 1/n_.

```{r, fig.width=7, fig.height=3, fig.cap="Study Year Frequencies", cache=TRUE}
dat %>%
  select(id, year) %>%
  unique() %>%
  ggplot(aes(x = as.factor(year))) +
    geom_bar(color = "black") +
  labs(x = "",
       y = "") +
  theme_bw()
```

## Frequency of Published Papers

Studies were included in our sample regardless of their publication status. From the `r length(unique(dat$id))` papers in the sample, `r as.numeric(table(unique(select(dat, id, published))$published)[1])` were published while `r as.numeric(table(unique(select(dat, id, published))$published)[2])` were not published.

```{r, fig.width=4, fig.height=3, fig.cap="Was the study published?", cache=TRUE}
dat %>%
  select(id, published) %>%
  unique() %>%
  ggplot(aes(x = as.factor(published))) +
    geom_bar(color = "black") +
  labs(x = "Published Study?",
       y = "") +
  theme_bw()
```

## Electoral System

Our sample differs considerably in regards to research design. One remarkable difference is that several authors apply the logics of the _law of 1/n_, which was built with majoritarian systems in mind, to non-majoritarian democracies. In the sample, `r as.numeric(table(unique(select(dat, id, elecsys2))$elecsys2)[1])` of the papers study *Majoritarian* systems while `r as.numeric(table(unique(select(dat, id, elecsys2))$elecsys2)[2])` study *Non-Majoritarian* electoral systems.\footnote{Note that for the \textit{law of 1/n} to be valid in a non-majoritarian system, we need to assume that despite the fact that politicians are able to campaign in every place in the district, the votes are geographically concentrated. The concentration facilitates politicians to use pork-barrel projects to captivate their electoral supporters.}

```{r, fig.width=4, fig.height=3, fig.cap="Electoral Systems", cache=TRUE}
dat %>%
  select(id, elecsys2) %>%
  unique() %>%
  ggplot(aes(x=as.factor(elecsys2))) +
    geom_bar(color = "black") +
  labs(x = "Electoral Systems",
       y = "") +
  theme_bw()
```

## Dependent Variables

The outcome variables included in the paper are:

- `r as.numeric(table(unique(select(dat, id, depvar2))$depvar2)[1])` Per Capita Expenditure papers
- `r as.numeric(table(unique(select(dat, id, depvar2))$depvar2)[3])` Natural Log of Per Capita Expenditure papers
- `r as.numeric(table(unique(select(dat, id, depvar2))$depvar2)[2])` Expenditure as a Percentage of the GDP papers

```{r, fig.width=4, fig.height=3, fig.cap="Dependent variables across the law of 1/n studies", cache=TRUE}
dat %>%
  select(id, depvar2) %>%
  unique() %>%
  mutate(depvar2 = factor(depvar2,
                          labels = c("Per Capita Expenditure",
                                     "Percentage GDP Government Expenditure",
                                     "Log Per Capita Expenditure"))) %>%
  ggplot(aes(x = depvar2)) +
    geom_bar(color = "black") +
  labs(x = "Dependent Variables",
       y = "") +
  coord_flip() +
  theme_bw()
```

## Independent Variables

Most of papers in our sample analyse the number of legislators in the lower house (`r as.numeric(table(unique(select(dat, id, indepvar2))$indepvar2)[2])`). The second most frequent independent variable is the number of legislators in the upper house (`r as.numeric(table(unique(select(dat, id, indepvar2))$indepvar2)[1])`). Finally, the minority of papers use the natural log of the number of legislators in the lower house as an independent variable (`r as.numeric(table(unique(select(dat, id, indepvar2))$indepvar2)[3])`). As we noted above, some papers had multiple coefficients, and thus the total number of coefficients is `r dim(dat)[2]`, while the number of papers is only `r length(unique(dat$id))`.

```{r, fig.width=4, fig.height=3, fig.cap="Independent variables across the law of 1/n studies", cache=TRUE}
dat %>%
  select(id, indepvar2) %>%
  unique() %>%
  mutate(indepvar2 = factor(indepvar2, labels = c("K (upper house legislators)",
                                                  "N (lower house legislators)",
                                                  "Log N"))) %>%
  ggplot(aes(x = indepvar2)) +
    geom_bar(color = "black") +
  labs(x = "Independent Variables",
       y = "") +
  coord_flip() +
  theme_bw()
```

## Histogram of the Coefficients and the Standard Errors

The coefficients in the papers vary considerably. In this section, we plot a histogram of the coefficients for all measurements included in the meta-analytic dataset.

Coefficients:

```{r, cache=TRUE, fig.width=5, fig.height=4}
dat %>%
  ggplot(aes(x = coef)) +
  geom_histogram(bins = 15, color = "black") +
  labs(x = "Coefficients") +
  theme_bw()
```

Standard errors:

```{r, cache=TRUE, fig.width=5, fig.height=4}
dat %>%
  ggplot(aes(x = SE)) +
  geom_histogram(bins = 10, color = "black") +
  labs(x = "Standard Errors") +
  theme_bw()
```

## Sign Coefficients

One simple statistic that we can compute to assess the validity of the _law of 1/n_ is the frequency of positive and negative estimates in the study sample. Below we plot the frequency for all the papers included in the meta-analytic dataset.

```{r, fig.width=5, fig.height=4, fig.cap="Coefficient Sign", cache=TRUE}
dat %>%
  ggplot(aes(x=as.factor(scoef))) +
  geom_bar(color = "black") +
  labs(x = "Coefficient Sign",
       y = "") +
  theme_bw()
```

# Descriptive Statistics of Moderators

We chose a set of moderators that frequently appear in the literature and may help us interpret our results. We included them in our meta-regressions alongside an indicator for the type of independent variable used in the original study ($n$, log($n$), or $k$). The additional moderators are: 1) electoral system; 2) data aggregation level; 3) estimation method; 4) publication year; 5) paper publication in an academic journal. The table below presents descriptive statistics for these moderators in our selection of articles.

```{r, warning=F,message=F, cache=TRUE}
fulldat$usemeta2 <- factor(fulldat$usemeta)
levels(fulldat$usemeta2) <- c("Other Coefficients", "Main Coefficients")
aux <- select(fulldat, usemeta2, indepvar2, year, published,
              elecsys2, method) %>%
  rename(`Independent Variables` = indepvar2,
         `Year` = year,
         `Published work` = published,
         `Electoral system` = elecsys2,
         `Estimation method` = method)

descrTable(~.-usemeta2, aux, y = aux$usemeta2,
           show.p.overall = F, show.all = T)
```

# Binomial Tests for Coefficient Signs

The _law of 1/n_ posits that we should expect a positive influence of legislature size on public expenditures. A general test of the theory could investigate whether the papers tend to find a higher frequency of positive coefficients in their estimations. In statistical terms, consider a random variable representing the coefficient sign for the papers. As each sign of the paper is a Bernoulli trial, the aggregate result for all papers follows a Binomial distribution with parameters $n$ equals the number of papers, and $p$ the  chance of a positive sign. The _law of 1/n_ can be reformulated as the chance of $p>0.5$, which facilitates the testing of the theory. The null hypothesis for such a test is that:

- $H_0$: the proportion of positive and negative signs are indistinguishable ($p=0.5$).

As we are taking an agnostic approach, we acknowledge that either the _law of 1/n_ ($p>0.5$), or the _reverse law of 1/n_ ($p<0.5$) could be true. In this case, the alternative hypothesis is $p\neq 0.5$. To perform this test, we run binomial tests in `R`, using the function `binom.test(.)`.

This test has two advantages. First, it is robust to the design of the paper. This is an important feature as papers analyse different countries, samples, and have distinct characteristics, such as whether they were published or not. All these factors increase the levels of study heterogeneity. The binomial test ignores the design discrepancies and focuses on the overall reported effect. Second, this test has the advantage of being straightforward and easy to interpret. It requires very few assumption and has a direct statistical formulation. The disadvantage is that we can extract more information from the articles with meta-regressions, as we see in the next sections.

For the number of legislators in the lower house ($N$), the results follow below.

```{r, cache=TRUE}
aux <- filter(dat, indepvar2 == "N")
aux2 <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p = 0.5)
aux2
```

Under the null hypothesis of $p=0.5$, we find that `r as.numeric(table(aux$scoef)[2])` studies, out of `r sum(table(aux$scoef))`, had a positive sign. The chance of a distribution with $p=0.5$ generate this sample is equal to p-value = `r round(as.numeric(aux2$p.value), 3)`. Therefore, we `r ifelse(as.numeric(aux2$p.value)<0.1, 'accept', 'reject')` the hypothesis that $p \neq 0.5$.

For the log of the number of legislators in the lower house ($\log(N)$), the results follow below.

```{r, cache=TRUE}
aux <- filter(dat, indepvar2 == "logN")
aux2 <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p = 0.5)
aux2
```

Out of `r sum(table(aux$scoef))`, `r as.numeric(table(aux$scoef)[2])` had a positive sign. The chance of a distribution with $p=0.5$ generate this sample is equal to p-value = `r round(as.numeric(aux2$p.value), 3)`. So we `r ifelse(as.numeric(aux2$p.value)<0.1, 'accept', 'reject')` the hypothesis that $p \neq 0.5$.

Finally, for the number of legislators in the upper house ($K$), the results are:

```{r, cache=TRUE}
aux <- filter(dat, indepvar2=='K')
aux2 <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p=0.5)
aux2
```

Here we see that `r as.numeric(table(aux$scoef)[2])` out of `r sum(table(aux$scoef))` had a positive sign. The p-value for this test is `r round(as.numeric(aux2$p.value), 3)`. Therefore, we `r ifelse(as.numeric(aux2$p.value)<0.1, 'accept', 'reject')` the hypothesis that $p \neq 0.5$. This is the only test that presents evidence of an association between the legislature size and expenditure.

\newpage

# Meta-Analysis

## Estimation Method

In general terms, there are two main ways to conduct a meta-analysis, either by using fixed effects or by employing random effects models. The fixed effects model assumes that there is one true effect in reality, and that all estimates are an attempt to uncover this true effect. The random effects model, in contrast, assumes that there is a distribution of true effects, and that the coefficients vary based on sample and tests characteristics.

In this paper, we use the random effects model. The empirical papers testing the _law of 1/n_ are very diverse. We tried to capture some of this diversity by considering the main dependent and independent variables separately, but they have at least three other important sources of dispersion:

1. **Subjects**: Counties, Municipalities, States, Provinces, Countries.
2. **Electoral systems**: Majoritarian, PR, Mixed.
3. **Modelling strategies**: Panel data, Standard OLS, IV, RDD.

These sources of heterogeneity have two implications. First, they make our estimates notably disperse. All but one of our heterogeneity tests are significant. When the sample sizes are large enough, we removed more heterogeneous studies, but we still had considerable dispersion in our estimates. Second, the amount of heterogeneity makes fixed effects estimates unrealistic and biased. Thus, we opt for random effects model.

Let each study having an effect of $T_i$. In a random effects model, we can decompose this effect into two components, the true effect that the study with the same specifications as $i$ comes from, $\theta_i$, and a within-study error $\varepsilon_i$:

\[
T_i \ = \ \theta_i + \varepsilon_i
\]

And the random effects model assumes that the $\theta_i$ varies from study to study, having a true parameter $\mu$, plus a between-study error, $\xi_i$:

\[
T_i \ = \ \mu + \xi_i + \varepsilon_i
\]

And the random effects model estimates the parameter $\mu$, under the challenge of estimating both the within-and-between-study sampling errors.

In all empirical estimates, we use the package `meta`, and the package `dmetar`, described in [Doing Meta-Analysis with R](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/random.html). To empirically implement the random effects model, we need to choose a method to estimate the true effect size variance, $\tau^2$, which in our formulation, represents the variance of $\xi_i$. We selected the **Restricted Maximum Likelihood Estimator**, as the literature regards it the most precise when analysing continuous measures, such as we have in our data.

We combined the three independent variables ($N$, $\log(N)$, and $K$) with our dependent variables of interest (Expenditure Per Capita, Log of Expenditure Per Capita, Expenditure as a Percentage of the GDP). This formed a $3 \times 3$ table, and in the following pages we present the results for each of these combinations.

## Lower House Size and Expenditure per Capita

```{r, cache=TRUE}
# Pooling effects analysis -- ExpPC x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'ExpPC')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

The forest plot:

```{r, fig.width=8, fig.height=4, fig.cap="Effect of lower houses size (N) on Per Capita Expenditure (ExpPC)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F, cache=TRUE}
f1 <- build_forest(mod, NULL, lsize = 15, ttl = 'Lower House Size\nand Expenditure per Capita')
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

### Electoral System Subgroup Analysis

The _law of 1/n_ was created for majoritarian systems. In the theoretical section below, we explain why the argument have potential issues when applied to non-majoritarian electoral systems. We estimated a subgroup analysis using a binary electoral system.

```{r, fig.width=8, fig.height=6, fig.cap="Subgroup Analysis of (N) x (ExpPC), controlling by electoral system",warning=FALSE, cache=TRUE}
build_forest_het(mod, capt = NULL, hetvar = aux$elecsys2)
```

Therefore, we can see that the hypothesis that majoritarian systems produce systematic positive effects was disproved. Both are non-significant, and they reassure us that the absense of effect is not caused by pooling multiple types of electoral systems.

## Log Lower House Size and Expenditure per Capita

There are no studies that have per capita expenditure as the dependent variable and log of lower house size as the treatment variable.

## Upper House Size and Expenditure per Capita

Now, we look into the upper house size (K). In this model, we investigate the effect of upper house size on expenditure per capita (ExpPC).

```{r, cache=TRUE}
# Pooling effects analysis -- ExpPC x K
aux <- dat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'ExpPC')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, fig.width=7, fig.height=4, fig.cap="Effect of upper house size (K) on the per capita government expenditure (ExpPC)",warning=FALSE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F}
f2 <- build_forest(mod, NULL, 15, ttl = 'Upper House Size\nand Expenditure Per Capita')
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Lower House Size and Log Expenditure Per Capita

This model estimates the Log of Per Capita Expenditure as the dependent variable, and the number of lower house legislators as the treatment variable.

```{r, cache=TRUE}
# Pooling effects analysis -- logExpPC x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'logExpPC')

mod <- metagen(
  coef, SE, data=aux,
  studlab=paste(authoryear),
  comb.fixed = FALSE,
  comb.random = TRUE,
  method.tau = "REML",
  hakn = TRUE,
  prediction = TRUE,
  sm="SMD"
  )

mod
```

The forest plot is as follows:

```{r, fig.width=8, fig.height=3, fig.cap="Effect of lower houses size (N) on log of per capita expenditure (logExpPC)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F, cache=TRUE}
f3 <- build_forest(mod, NULL, 15, ttl = 'Lower House Size\nand Log Expenditure Per Capita')
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Log of Lower House Size and Log of Expenditure Per Capita

In this specification, we study the log of per capita expenditure (logExpPC) as a function of the log of lower house size (logN).

```{r, cache=TRUE}
# Pooling effects analysis -- logExpPC x logN
aux <- dat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'logExpPC')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

The forest plot is available below:

```{r, fig.width=8, fig.height=4, fig.cap="Effect of log lower houses size (logN) on the log of per capita government expenditure (logExpPC)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F, cache=TRUE}
f4  <- build_forest(mod, NULL, 15, ttl = 'Log of Lower House Size\nand Log of Expenditure Per Capita')
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`). **This model is significant at the 10\% confidence level.**
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Log of Upper House Size and Log of Expenditure Per Capita

No studies correlate the log of per capita expenditure with the size of upper house (K).

## Lower House Size and Expenditure as Percentage of GDP

This model fits the random effects for the percentage of GDP as public expenditure as the main outcome, and the size of lower house as the treatment variable.

```{r, cache=TRUE}
# Pooling effects analysis -- PCTGDP x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'PCTGDP')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

Below, you may find the forest plot:

```{r, fig.width=8, fig.height=3, fig.cap="Effect of lower houses size (N) on percentage of public expenditure GDP (PCTGDP)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F, cache=TRUE}
f5 <- build_forest(mod, NULL, 15, ttl = 'Lower House Size\nand Expenditure as Percentage of GDP')
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Log Lower House Size and Expenditure as Percentage of GDP

This model investigates the percentage of GDP as public expenditure as the dependent variable and the log lower house size (logN) as the treatment variable.

```{r, cache=TRUE}
# Pooling effects analysis -- PCTGDP x logN
aux <- dat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'PCTGDP')

mod <- metagen(
  coef, SE, data=aux,
  studlab=paste(authoryear),
  comb.fixed = FALSE,
  comb.random = TRUE,
  method.tau = "REML",
  hakn = TRUE,
  prediction=TRUE,
  sm="SMD"
  )

mod
```

The forest plot follows below:

```{r, fig.width=8, fig.height=4, fig.cap="Effect of log lower houses size (logN) on the GDP share of public expenditure (PCTGDP)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F, cache=TRUE}
f6 <- build_forest(mod, NULL, 15, ttl = 'Log Lower House Size\nand Expenditure as Percentage of GDP')
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Upper House Size and Expenditure as Percentage of GDP

This model looks into the effect of upper house size (K) on the public expenditure share of the GDP (PCTGDP).

```{r, cache=TRUE}
# Pooling effects analysis -- PCTGDP x K
aux <- dat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'PCTGDP')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

The forest plot follows below:

```{r, fig.width=8, fig.height=4, fig.cap="Effect of upper house size (K) on the public expenditure share of the GDP (PCTGDP)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F, cache=TRUE}
f7 <- build_forest(mod, NULL, 15, ttl = 'Upper House Size\nand Expenditure as Percentage of GDP')
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Lower House Size and Expenditure per Capita (IV)

```{r, cache=TRUE}
# Pooling effects analysis -- ExpPC x N (IV only)
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'ExpPC',
         method %in% c('IV'))

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, fig.width=8, fig.height=4, fig.cap="Effect of lower houses size (N) on Per Capita Expenditure (ExpPC)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F, cache=TRUE}
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'ExpPC')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
f8 <- build_forest_het(mod, NULL, lsize = 15, ttl = 'Lower House Size and Expenditure per Capita\n(subgrouping by the estimation technique)', hetvar = aux$method)
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

### Regression Method Subgroup Analysis

Over time, the literature evolved to use causally identified techniques for determine the effect of legislature size on the expenduture per capita. To study whether the method had an effect on the estimated coefficients, we fit a subgroup analysis using the method employed in each paper.

```{r, fig.width=8, fig.height=6, fig.cap="Subgroup Analysis of (N) x (ExpPC), controlling by regression methods",warning=FALSE, cache=TRUE}
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'ExpPC')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")

build_forest_het(mod, capt = NULL, hetvar = aux$method)
```

Although all methods generate a null effect, the IV method seems to be well distributed, with two papers with positive effects and two papers negative displaying negative effects. The random effects model for the subgroup is 0.22, which is negative but non-significant. Improve the estimation technique, for the case of IVs, render still a null effect of legislature size on per capita government expenditure.

## Lower House Size and Log of Expenditure per Capita (RDD)

```{r, cache=TRUE}
# Pooling effects analysis -- logExpPC x N (RDD only)
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'logExpPC',
         method == 'RDD')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

Forest plot:

```{r, fig.width=8, fig.height=4, fig.cap="Effect of lower houses size (N) on Per Capita Expenditure (ExpPC)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F, cache=TRUE}
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'logExpPC')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
f9 <- build_forest_het(mod, NULL, lsize = 15, ttl = 'Lower House Size and Log of Expenditure per Capita\n(subgrouping by the estimation technique)', hetvar = aux$method)
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

### Regression Method Subgroup Analysis

Over time, the literature evolved to use causally identified techniques for determine the effect of legislature size on the log of expenduture per capita. To study whether the method had an effect on the estimated coefficients, we fit a subgroup analysis using the method employed in each paper.

```{r, fig.width=8, fig.height=6, fig.cap="Subgroup Analysis of (N) x (logExpPC), controlling by the regression methods",warning=FALSE, cache=TRUE}
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'logExpPC')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")

build_forest_het(mod, capt = NULL, hetvar = aux$method)
```

For the RDD subgroup analysis, we can see a much clearer picture. All estimates are negative, and the subgroup effect is -0.11. This suggests that improving the estimation renders to a negative result that is likely to hold conditional on more papers using the technique displaying the same effect size and sign.

# Code for the Main Graphs

## Figure 1

```{r, echo=T, warning=F, cache=TRUE}
pdf('../graphs/graph1.pdf', width = 16, height = 11)
ggarrange(f1,f3,f5,f4,f6,f2,f7, align = 'hv')
dev.off()
```

## Figure 2

```{r, echo=T, warning=F, cache=TRUE}
pdf('../graphs/graph2.pdf', width = 12, height = 6)
ggarrange(f8, f9, align = 'hv')
dev.off()
```

# Meta-Analysis (All Coefficients)

## Lower House Size and Expenditure Per Capita

Here we estimate the relationship between expenditure per capita as a dependent variable, and the lower house size as the independent variable.

```{r, warning=F, cache=T}
# Pooling effects analysis -- ExpPC x N
aux <- fulldat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'ExpPC')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

The forest plot:

```{r, fig.width=12, fig.height=11, fig.cap="Effect of Lower House Size (N) on Per Capita Expenditure (ExpPC)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

### Electoral System Subgroup Analysis

The _law of 1/n_ was formulated to analyse the budgetary allocation in majoritarian systems. In the theoretical section below, we explain why the argument have potential issues when applied to non-majoritarian electoral systems. We estimated a subgroup analysis using a dummy variable indicating the electoral system included in each model.

```{r, fig.width=8, fig.height=9, fig.cap="Subgroup Analysis of (N) x (ExpPC), controlling by electoral system",warning=FALSE, cache=T}
mod2 <- tibble(
  TE = mod$TE,
  seTE = mod$seTE,
  studlab = mod$studlab,
  lower = mod$lower,
  upper = mod$upper,
  group = "A") %>%
  bind_rows(.,
            aux = tibble(
              TE = c(mod$TE.random, NA),
              seTE = c(mod$seTE.random, NA),
              studlab = c("Overall Effect", "Prediction Interval"),
              lower = c(mod$lower.random, mod$lower.predict),
              upper = c(mod$upper.random, mod$upper.predict),
              group = "B")) %>%
  group_by(studlab) %>%
  mutate(studlab2 = paste0(studlab, "_", 1:n())) %>%
  ungroup()

f8b <- mod2 %>%
  ggplot(aes(y = reorder(studlab2,TE), x = TE, xmin = lower, xmax = upper)) +
  # Studies coefs
  geom_point(aes(color = group)) +
  # Error Bars
  geom_errorbarh(aes(color = group), height = 0.1) +
  # Colors
  scale_color_manual(values = c("#000000", "#8b0000")) +
  # X-axis limit
  scale_x_continuous(limits=c(1.2*(min(mod2$lower)), 1.2*(max(mod2$upper)))) +
  # Y-axis names
  scale_y_discrete(labels = function(x) str_replace(x, "_[0-9]*$", "")) +
  # Vertical dashed line
  geom_vline(xintercept=0, color="#000000", linetype="dashed") +
  # Labels
  labs(x = "",
       y = "") +
  # Facet - Separating Studies from Overall Effect
  facet_grid(group~., scales = "free", space = "free") +
  # Theme
  theme_minimal() %+replace%
  theme(strip.text.y = element_blank(),
        legend.position = "none",
        axis.text.y = element_text(size = 13, hjust = 1.1),
        axis.text.x = element_text(size = 15, hjust = 1.1))
f8b
```

Therefore, we see that majoritarian systems do not have a clear positive effect on budgetary spending. The majoritarian systems in the sample had a random effects model estimate of -0.25, while the random effects model in the non-majoritarian subgroup fitted a value of 0.08. Both are non-significant, but they reassure us that the absence of effect is not caused by pooling multiple types of electoral systems.

## Log of Lower House Size and Expenditure Per Capita

There are no studies that have per capita expenditure as the dependent variable and log of lower house size as the treatment variable.

## Upper House Size and Expenditure Per Capita

Now we investigate the effect of the upper house size ($K$) on government spending. In the model below, we evaluate the relationship between upper house size and expenditure per capita (ExpPC).

```{r, warning=F, cache=TRUE}
# Pooling effects analysis -- ExpPC x K
aux <- fulldat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'ExpPC')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, fig.width=9, fig.height=8, fig.cap="Effect of upper house size (K) on the per capita government expenditure (ExpPC)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Lower House Size and Log of Expenditure Per Capita

This model estimates the log of per capita expenditure as the dependent variable, and the number of lower house legislators as the treatment variable.

```{r, warning=F, cache=TRUE}
# Pooling effects analysis -- logExpPC x N
aux <- fulldat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'logExpPC')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

The forest plot is shown below:

```{r, fig.width=8, fig.height=5, fig.cap="Effect of lower houses size (N) on log of per capita expenditure (logExpPC)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Log of Lower House Size and Log of Expenditure Per Capita

In this specification, we study the log of per capita expenditure (logExpPC) as a function of the log of lower house size (logN).

```{r, warning=F, cache=TRUE}
# Pooling effects analysis -- logExpPC x logN
aux <- fulldat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'logExpPC')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

The forest plot:

```{r, fig.width=8, fig.height=4, fig.cap="Effect of log lower houses size (logN) on the log of per capita government expenditure (logExpPC)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`). **This model is significant at the 10\% confidence level.**
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Upper House Size and Log of Expenditure Per Capita

No studies related the log of per capita expenditure with the size of upper house ($K$).

## Lower House Size and Expenditure as Percentage of GDP

This model fits the random effects for the percentage of GDP as public expenditure as the main outcome, and the size of lower house as the treatment variable.

```{r, warning=F, cache=TRUE}
# Pooling effects analysis -- PCTGDP x N
aux <- fulldat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'PCTGDP')

mod <- metagen(coef, SE, data = aux,
          studlab = paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm = "SMD")
mod
```

Here is the forest plot:

```{r, fig.width=8, fig.height=6, fig.cap="Effect of lower houses size (N) on percentage of public expenditure GDP (PCTGDP)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Log of Lower House Size and Expenditure as Percentage of GDP

This meta-regression investigates the percentage of GDP as public expenditure as the dependent variable and the natural logarithm of lower house size (log($N$)) as the treatment variable.

```{r, warning=F, cache=TRUE}
# Pooling effects analysis -- PCTGDP x logN
aux <- fulldat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'PCTGDP')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

The forest plot:

```{r, fig.width=8, fig.height=4, fig.cap="Effect of log lower houses size (logN) on the GDP share of public expenditure (PCTGDP)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Upper House Size and Expenditure as Percentage of GDP

This model looks into the effect of upper house size ($K$) on the public expenditure share of the GDP (PCTGDP).

```{r, warning=F, cache=TRUE}
# Pooling effects analysis -- PCTGDP x K
aux <- fulldat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'PCTGDP')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, fig.width=8, fig.height=5, fig.cap="Effect of upper house size (K) on the public expenditure share of the GDP (PCTGDP)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Lower House Size and Expenditure per Capita (IV)

```{r, cache=TRUE}
# Pooling effects analysis -- ExpPC x N (IV only)
aux <- fulldat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'ExpPC',
         method %in% c('IV'))

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, fig.width=8, fig.height=4, fig.cap="Effect of lower houses size (N) on Per Capita Expenditure (ExpPC)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```


Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## Lower House Size and Log of Expenditure per Capita (RDD)

```{r, cache=TRUE}
# Pooling effects analysis -- ExpPC x N
aux <- fulldat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'logExpPC',
         method == 'RDD')

mod <- metagen(coef, SE, data=aux,
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, fig.width=8, fig.height=4, fig.cap="Effect of lower houses size (N) on Per Capita Expenditure (ExpPC)",warning=FALSE, cache=TRUE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 =$ `r round(mod$I2*100, 2)`.
2. The estimated SMD in the random effects model is $g =$ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

\newpage

# Meta-Regressions

## Meta-Regressions for Expenditure as a Percentage of the GDP

In this section, we show the coefficients for our meta-regressions. We start with expenditure as a percentage of GDP as the dependent variable.

```{r, warning=F, cache=T}
mod <-  rma(yi = coef,
              sei = SE,
              data = dat,
              method = "REML",
              mods = ~indepvar2+year+published+elecsys2+method,
              test = "knha",
            subset = dat$depvar2=='PCTGDP',
            slab = dat$authoryear)

mod1 <- tibble(
     ` ` = c("Intercept",
             "Indepvar: N",
             "Indepvar: logN",
             "Year",
             "Elecsys: Non-Majoritarian",
             "Method: Panel"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4), ")"),
  model = "PCTGDP"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 4)))
```

```{r, warning=F, cache=T}
summary(mod)
```

As we have considerable heterogeneity in our sample, we run a permutation test to ensure the validity of our estimates. The results follow below.

```{r, warning=F, cache=T}
mod <- permutest(mod, progbar = F)
mod

mod1_permu <- tibble(
     ` ` = c("Intercept",
             "Indepvar: N",
             "Indepvar: logN",
             "Year",
             "Elecsys: Non-Majoritarian",
             "Method: Panel"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "PCTGDP - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

We have the following results for the meta-regressions of Expenditure as a Percentage of GDP:

1. Compared with `K`, models with `N` and `logN` find significantly negative coefficients.
2. Year has null effect.
3. Unpublished papers tend to have higher coefficients than published papers.
4. Passing from `Majoritarian` to `Non-Majoritarian`, decreases significantly the effects found in our models.
5. In terms of modelling, passing from `OLS` to `PANEL` increases the detected effects.
6. When passing from `Country` to `Cross-Country`, it has no effect on the estimated coefficients.

Below we also run the meta-regressions adding all coefficients in the papers. The results follow below:

```{r, warning=F, cache=T}
mod <- rma(yi = coef,
              sei = SE,
              data = fulldat,
              method = "REML",
              mods = ~ indepvar2+year+published+elecsys2+method,
              test = "knha",
            subset = fulldat$depvar2=='PCTGDP',
            slab = fulldat$authoryear)

mod2 <- tibble(
  ` ` = c("Intercept",
          "Indepvar: N",
          "Indepvar: logN",
          "Year",
          "Elecsys: Non-Majoritarian",
          "Method: Panel"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "PCTGDP - All coefs"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

```{r, warning=F, cache=T}
summary(mod)
```

```{r, warning=F, cache=T}
mod <- permutest(mod, progbar = F)
mod

mod2_permu <- tibble(
     ` ` = c("Intercept",
             "Indepvar: N",
             "Indepvar: logN",
             "Year",
             "Elecsys: Non-Majoritarian",
             "Method: Panel"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "PCTGDP - All coefs - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

For all the coefficients, we have the following results:

1. Compared with `K`, models with `N` and `logN` tend to have significantly negative coefficients.
2. Year has a positive effect: the younger the publication, the higher the detected coefficient.
3. Unpublished papers tend to have higher coefficients than published papers.
4. Passing from `Majoritarian` to `Non-Majoritarian` significantly decreases the effects found in our models.
5. Regarding statistical models, passing from `OLS` to `PANEL` increases the detected effects.

## Meta-Regressions for Expenditure Per Capita

Here we do the same exercise with expenditure per capita as the main outcome.

```{r, error=F, warning=F, cache=T}
mod <-  rma(yi = coef,
              sei = SE,
              data = dat,
              method = "REML",
              mods = ~indepvar2+year+published+elecsys2+method,
              test = "knha",
            subset = dat$depvar2=='ExpPC',
            slab = dat$authoryear,
            control=list(maxiter=1000))

mod3 <- tibble(
  ` ` = c("Intercept",
          "Indepvar: N",
          "Year",
          "Published: No",
          "Elecsys: Non-Majoritarian",
          "Method: Panel",
          "Method: IV"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "ExpPC"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

```{r, warning=F, cache=T}
summary(mod)
```
As we have considerable heterogeneity in our sample, we run a permutation test to ensure the validity of our estimates. The results follow below.

```{r, error=F, warning=F, cache=T}
mod <- permutest(mod, progbar = F)
mod

mod3_permu <- tibble(
  ` ` = c("Intercept",
          "Indepvar: N",
          "Year",
          "Published: No",
          "Elecsys: Non-Majoritarian",
          "Method: Panel",
          "Method: IV"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "ExpPC - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

We have the following results for the meta-regressions of Expenditure Per Capita:

1. Compared with `K`, models with `N` tend to detect significantly smaller effects.
2. Year has null effect.
3. `Majoritarian`, when compared to `Non-Majoritarian` electoral systems, significantly increase per capita expenditure.
4. Regarding statistical models, passing from `OLS` to `PANEL` or `IV` increases the detected effects.

We also run the meta-regressions adding all coefficients in the papers. The results follow below:

```{r, warning=F, cache=T}
mod <- rma(yi = coef,
              sei = SE,
              data = fulldat,
              method = "REML",
              mods = ~ indepvar2+year+published+elecsys2+method,
              test = "knha",
            subset = fulldat$depvar2=='ExpPC',
            slab = fulldat$authoryear)

mod4 <- tibble(
  ` ` = c("Intercept",
          "Indepvar: N",
          "Year",
          "Published: No",
          "Elecsys: Non-Majoritarian",
          "Method: Panel",
          "Method: IV"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "ExpPC - All coefs"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

```{r, warning=F, cache=T}
summary(mod)
```

```{r, warning=F, cache=T}
mod <- permutest(mod, progbar = F, iter = 100)
mod

mod4_permu <- tibble(
  ` ` = c("Intercept",
          "Indepvar: N",
          "Year",
          "Published: No",
          "Elecsys: Non-Majoritarian",
          "Method: Panel",
          "Method: IV"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "ExpPC - All coefs - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

With all coefficients, the results of the effect sizes on the Expenditure Per Capita regressions are the following:

1. Compared with `K`, models with `N` tend to detect significantly smaller effects.
2. Year has now a positive effect on coefficient sizes.
3. `Majoritarian`, when compared to `Non-Majoritarian` electoral systems, significantly increase per capita expenditure.
4. Regarding statistical models, passing from `OLS` to `PANEL` decreases the detected effects.
5. All other coeffients were not significant.

## Meta-Regressions for the Log of Expenditure Per Capita

Lastly, we run the model with the natural logarithm of expenditure per capita.

```{r, warning=F, cache=T}
mod <- rma(yi = coef,
              sei = SE,
              data = dat,
              method = "REML",
              mods = ~indepvar2+year+published+elecsys2+method,
              test = "knha",
            subset = dat$depvar2=='logExpPC',
            slab = dat$authoryear)

mod5 <- tibble(
   ` ` = c("Intercept",
           "Indepvar: N",
           "Year",
           "Published: No",
           "Method: Panel"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "logExpPC"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

```{r, warning=F, cache=T}
summary(mod)
```

As we have considerable heterogeneity in our sample, we run a permutation test to ensure the validity of our estimates. The results follow below.

```{r, warning=F, cache=T}
mod <- permutest(mod, progbar = F)
mod

mod5_permu <- tibble(
  ` ` = c("Intercept",
          "Indepvar: N",
          "Year",
          "Published: No",
          "Method: Panel"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "logExpPC - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))

mod5_permu %>%
  select(-model) %>%
  kable(booktabs = T,align = "c",linesep ='') %>%
  kable_styling(c("striped","bordered"), position = "center")
```

We have the following results for the meta-regressions of Log of Expenditure Per Capita:

1. Unpublished papers report significantly higher coefficients.
2. Moving from `OLS` to `PANEL` increases the detected effects.
3. All other coefficients remained insignificant.

Below we also run the meta-regressions adding all coefficients in the papers. The results follow below:

```{r, warning=F, cache=T}
mod <- rma(yi = coef,
              sei = SE,
              data = fulldat,
              method = "REML",
              mods = ~ indepvar2+year+published+elecsys2+method,
              test = "knha",
            subset = fulldat$depvar2=='logExpPC',
            slab = fulldat$authoryear)

mod6 <- tibble(
  ` ` = c("Intercept",
          "Indepvar: N",
          "Year",
          "Published: No",
          "Method: Panel",
          "Method: RDD"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4), ")"),
  model = "logExpPC - All coefs"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

```{r, warning=F, cache=T}
summary(mod)
```

```{r, warning=F, cache=T}
mod <- permutest(mod, progbar = F)

mod6_permu <- tibble(
  ` ` = c("Intercept",
          "Indepvar: N",
          "Year",
          "Published: No",
          "Method: Panel",
          "Method: RDD"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4), ")"),
  model = "logExpPC - All coefs - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

With all coefficients, the results of the effect sizes on the Log of Expenditure Per Capita Regressions are the following:

1. In terms of the modelling, passing from `OLS` to `PANEL` or `RDD` decreases the detected effects.
2. All other coefficients remained insignificant.

\newpage 

# Robustness: Meta-Regressions (All Coefficients)

In this section, we aggregate all the coefficients and run a multivariate meta-regression, controlling for:

1. The type of the dependent variable in the study (expenditure per capita, log of the expenditure per capita, and share of government expenditure in the GDP)
2. The type of the independent variable in the study ($N$, $K$, $log (N)$);
3. The electoral system (Majoritarian, Proportional Representation, and Mixed).

The results follow below, and show null effects for all variables, including the intercept.

```{r, warning=F, cache=T}
mod <-  rma(yi = coef,
              sei = SE,
              data = dat,
              method = "REML",
              mods = ~ depvar2+indepvar2+year+published+elecsys2+method,
              test = "knha")
```

```{r}
summary(mod)
```

As we have considerable heterogeneity in our sample, we run a permutation test to ensure the validity of our estimates. The results follow below.

```{r, cache=T}
permutest(mod, progbar = F)
```

In the main text, we selected coefficients based on the regressions that had most observations and presented a full model (with fixed effects or intermediate bandwidth in RDD). We also run the meta-regressions adding all coefficients in the papers. The results follow below:

```{r, warning=F, cache=T}
mod <- rma(yi = coef,
              sei = SE,
              data = fulldat,
              method = "REML",
              mods = ~ depvar2+indepvar2+year+published+elecsys2+method,
              test = "knha")
```

```{r, cache=T}
summary(mod)
```

```{r, cache=T}
permutest(mod, progbar = F)
```

\newpage 

# Auxiliary Functions

## Function to Generate Meta-Analytic Figures

This function receives the meta-analysis results and builds a forest plot using `ggplot2`.

```{r, eval = FALSE, cache=T}
# Build plot function for forest plots
build_forest <- function(mod, capt, lsize = 22, ttl = NULL) {
  # Build dataset for plot
  mod2 <- tibble(
    TE = mod$TE,
    seTE = mod$seTE,
    studlab = mod$studlab,
    lower = mod$lower,
    upper = mod$upper,
    group = "A") %>%
    bind_rows(.,
              aux = tibble(
                TE = c(mod$TE.random, NA),
                seTE = c(mod$seTE.random, NA),
                studlab = c("Overall Effect", "Prediction Interval"),
                lower = c(mod$lower.random, mod$lower.predict),
                upper = c(mod$upper.random, mod$upper.predict),
                group = "B")) %>%
    group_by(studlab) %>%
    mutate(studlab2 = paste0(studlab, "_", 1:n())) %>%
    ungroup()

  # Graph limits
  limg <- max(abs(c(mod2$lower, mod2$upper)))

  # Build plot
  p <- mod2 %>%
    ggplot(aes(y = reorder(studlab2, TE),
               x = TE, xmin = lower, xmax = upper)) +
    geom_point(aes(color = group)) +
    geom_errorbarh(aes(color = group), height = 0.1) +
    scale_color_manual(values = c("#000000", "#8b0000")) +
    scale_x_continuous(limits=c(-1.1*limg, 1.1*limg)) +
    scale_y_discrete(
      labels = function(x) str_replace(x, "_[0-9]*$", "")) +
    geom_vline(xintercept = 0,
               color = "#000000", linetype = "dashed") +
    labs(x = "",
         y = "") +
    facet_grid(group~., scales = "free", space = "free") +
    labs(caption = capt,
         title = ttl) +
    theme_minimal() %+replace%
    theme(strip.text.y = element_blank(),
          legend.position = "none",
          axis.text.y = element_text(size = .8 * lsize,
                                     hjust = 1),
          axis.text.x = element_text(size = .6 * lsize,
                                     hjust = 1.1),
          plot.caption = element_text(size = lsize),
          plot.title.position = "plot",
          plot.title = element_text(hjust = 0.5,
                                    face = "bold",
                                    margin = margin(0, 0, 10, 0)),
          panel.grid.major = element_blank())
  return(p)
}

# Build plot function for forest plots to heterogeneous subgroup analysis
build_forest_het <- function(mod, capt, lsize = 22, ttl = NULL, hetvar = NULL) {
  mod <- update(mod, byvar = hetvar, print.byvar = F)

  # Build dataset for plot
  mod2 <- tibble(
    byvar = mod$byvar,
    TE = mod$TE,
    seTE = mod$seTE,
    studlab = mod$studlab,
    lower = mod$lower,
    upper = mod$upper,
    group = "A") %>%
    arrange(byvar)
  auxmod <- tibble()
  for (i in rev(mod$bylevs)){
    auxmod <- rbind(auxmod, tibble(byvar = i,
                    TE = NA,
                    seTE = NA,
                    studlab = toupper(i),
                    lower = NA,
                    upper = NA,
                    group = "B"))
    auxmod <- rbind(auxmod,
                    filter(mod2, byvar==i) %>%
                      arrange(desc(TE)))
    auxmod <- rbind(auxmod, tibble(
      byvar = i,
      TE = mod$TE.random.w[which(mod$bylevs==i)],
      seTE = mod$seTE.random.w[which(mod$bylevs==i)],
      studlab = 'Subgroup Effect',
      lower = mod$lower.random.w[which(mod$bylevs==i)],
      upper = mod$upper.random.w[which(mod$bylevs==i)],
      group = "B"))
  }
  auxmod <- rbind(auxmod, tibble(
    byvar = NA,
    TE = c(mod$TE.random, NA),
    seTE = c(mod$seTE.random, NA),
    studlab = c("Overall Effect", "Prediction Interval"),
    lower = c(mod$lower.random, mod$lower.predict),
    upper = c(mod$upper.random, mod$upper.predict),
    group = "B"))
  mod2 <- data.frame(auxmod)
  mod2$byvar <- toupper(mod2$byvar)
  TEaux <- mod2$TE
  TEaux[mod2$studlab== 'Subgroup Effect'] = TEaux[mod2$studlab== 'Subgroup Effect'] - 100

  # Graph limits
  limg <- max(abs(c(mod2$lower, mod2$upper)))

  # Build plot
  p <- mod2 %>%
    ggplot(aes(y = reorder(studlab, TEaux),
               x = TE, xmin = lower, xmax = upper)) +
    geom_point(aes(color = group)) +
    geom_errorbarh(aes(color = group),
                   height = 0.1) +
    scale_color_manual(values = c("#000000", "#8b0000")) +
    scale_x_continuous(limits = c(-1.1 * limg, 1.1 * limg)) +
    scale_y_discrete(
      labels = function(x)
        str_replace(x, "_[0-9]*$", "")) +
    geom_vline(xintercept = 0,
               color = "#000000", linetype = "dashed") +
    labs(x = "",
         y = "") +
    facet_grid(byvar~., scales = "free", space = "free") +
    labs(caption = capt,
         title = ttl) +
    theme_minimal() %+replace%
    theme(strip.text.y = element_blank(),
          legend.position = "none",
          axis.text.y = element_text(size = .8 * lsize,
                                     hjust = 1),
          axis.text.x = element_text(size = .6 * lsize,
                                     hjust = 1.1),
          plot.caption = element_text(size = lsize),
          plot.title.position = "plot",
          plot.title = element_text(hjust = 0.5,
                                    face = "bold",
                                    margin = margin(0, 0, 10, 0)),
          panel.grid.major = element_blank())
  return(p)
}
```

## Webscraping Code
\label{sub:scrap}

We used the code below to download the articles cited in our paper.

```{r, eval = FALSE, cache=T}
# Required packages
pkgs <- c("tidyverse", "rvest", "RSelenium")

# Install the packages if necessary
installIfNot <- function(x) {
  if (x %in% rownames(installed.packages()) == FALSE)
    install.packages(x, dependencies = T,
					 repos = "http://cran.us.r-project.org")
}
lapply(pkgs, installIfNot)

# Load packages
lapply(pkgs, require, character.only = T)
rm(pkgs, installIfNot)

# Setting Up Selenium

# Alternative 1: Setting up Selenium (head)
rsD <- rsDriver(port = 1114L, browser = c("firefox"))
remDr <- rsD$client
remDr$open()

# Google Scholar

# site: https://scholar.google.com
remDr$navigate("https://scholar.google.com/
               scholar?cites=13117579863846712459&as_sdt=2005&sciodt=0,5")

articles_weingast <- tibble(
  value = NA,
  term = NA,
  page = NA
)

k <- 0

for (j in 1:213) { # we had to manually choose the number of pages here

  Sys.sleep(rpois(1, 5))

  # Getting articles basic information
  k <- k + 1

  webElem <- remDr$findElement("css", "body")


  title <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(
      xpath = '//*[contains(concat( " ", @class, " " ),
      concat( " ", "gs_rt", " " ))]'
      ) %>%
    html_text() %>%
    enframe(name = NULL) %>%
    rename("title" = "value") %>%
    mutate(page = k)

  articles_partial <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "gs_a", " " ))]') %>%
    html_text() %>%
    enframe(name = NULL) %>%
    bind_rows(
      tibble(
        value = "delete",
        term = NA,
        page = NA
      ),
      .
    ) %>%
    bind_cols(., title)


  # Binding articles
  articles_weingast <- bind_rows(articles_weingast, articles_partial)

  # Changing Pages
  next_button <- remDr$findElement(using = "xpath", "/html/body/div/div[11]/div[2]/div[2]/div[3]/
                                   div[2]/center/table/tbody/tr/td[12]/a/b")
  next_button$clickElement()
  # Deleting cookies
  remDr$deleteAllCookies()
}

write_csv(articles_weingast, "scholar_weingast_raw.csv")

articles_weingast <- articles_weingast %>%
  select(-term, -page) %>%
  filter(value != "delete") %>%
  slice(2:nrow(.)) %>%
  filter(!grepl("books.google.com", value)) %>%
  filter(!grepl("BOOK", title)) %>%
  separate(., value, into = c("author", "value"),
           sep = " -", remove = T, extra = "merge", fill = "right") %>%
  separate(., value, into = c("journal", "year"),
           sep = ",", remove = T, extra = "merge", fill = "right") %>%
  mutate(
    year_2 = ifelse(is.na(year), journal, year),
    journal = ifelse(is.na(year), NA, journal),
    year = year_2
  ) %>%
  select(-year_2) %>%
  separate(., year, into = c("year", "site"),
           sep = "-", remove = T, extra = "merge", fill = "right") %>%
  mutate(
    year = gsub("[^0-9 ]", "", value),
    year = gsub("^[0-9]{5,}", "", year),
    year = gsub("^ {1,}", "", year)
  ) %>%
  separate(., year, into = c("year", "junk"),
           sep = " ", remove = T, extra = "merge", fill = "right") %>%
  separate(., value, into = c("journal", "value"),
           sep = "-", remove = T, extra = "merge", fill = "right") %>%
  mutate(
    journal_untidy = year,
    year = gsub("[^0-9 ]", "", year)
  )

articles <- articles %>%
  na.omit() %>%
  distinct(., value, .keep_all = T)

write_csv(articles, "google_scholar_clean.csv")

# Scopus

# url: https://www.scopus.com/home.uri

# Scraping Scopus requires a bit more manual labor.
# You can login on scopus through your university/institution
# and download the metadata of the article(s) you
# want directly from there.
# All we need to do after that is scrape the information of
# every link from the .csv file downloaded previously

scopus <- read_csv("scopus.csv")

scopus <- scopus %>%
  mutate(article = map_chr(Link, ~ {
    remDr$navigate(.x)
    read_html(remDr$getPageSource()[[1]]) %>%
      html_nodes(xpath = '//*[(@id = "abstractSection")]//p') %>%
      html_text() %>%
      paste(., collapse = "\r\n")
  })) %>%
  mutate(
    article = gsub(
      '\r\n\nUse this section.*Topics\n\n\n"',
      "",
      article
    ),
    article = gsub(
      "Topics are unique.*onwards.",
      "",
      article
    ),
    article = gsub(
      "Use this section.*documents.",
      "",
      article
    ),
    article = gsub(
      "Learn more about these Topics",
      "",
      article
    ),
    article = gsub(
      ". 20.*, Springer Science\\+Business Media, LLC, part of Springer Nature.",
      "",
      article
    ),
    article = gsub("\r", "", article),
    article = gsub("\n", "", article),
    article = gsub(" {2,}", " ", article),
    article = gsub(" {3,}", "", article)
  )

write_csv(scopus, "scopus_clean.csv")

#### Microsoft Academic ####

# url: https://academic.microsoft.com/home
articles <- list()
k <- 0
remDr$navigate("https://academic.microsoft.com/paper/
               2076316673/citedby/search?q=The%20Political%
               20Economy%20of%20Benefits%20and%20Costs%3A%20A%
               20Neoclassical%20Approach%20to
               %20Distributive%20Politics&qe=RId%253D2076316673&f=&orderBy=0")


# 1) Getting hyperlinks from articles
for (j in 1:100) {
  k <- k + 1
  print(k)

  # Navigating Website

  Sys.sleep(rpois(2, 5))

  # Getting articles' links
  articles[[k]] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(xpath = "//a") %>%
    html_attr("href") %>%
    enframe(name = NULL) %>%
    filter(
      grepl("paper/", value),
      !grepl("citedby", value)
    ) %>%
    mutate(value = paste0("https://academic.microsoft.com/", value))

  # Changing Page
  next_page_others <- remDr$findElement(using = "xpath", "/html/body/div/div/div/router-view/router-view/                                        ma-edp-serp/div/div[2]/div/
  compose/div/div[2]/ma-pager/div/i[2]")
  next_page_others$clickElement()
}


articles <- articles %>%
  reduce(bind_rows) %>%
  distinct(value, .keep_all = T)

# 2) Navigating through articles and scraping them

articles_links <- articles %>%
  mutate(
    abstract = NA,
    title = NA,
    year = NA,
    journal = NA,
    authors = NA,
    tags = NA
  )

for (i in 1:nrow(articles_links)) {
  remDr$navigate(articles_links$value[i])
  Sys.sleep(rpois(1, 4))

  articles_links$abstract[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(., xpath = "//html/body/div/div/div/router-view/compose[1]/
               div/div/ma-entity-detail-info/compose/div/div/div[1]/p") %>%
    html_text() %>%
    paste(., collapse = " ")

  articles_links$title[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(.,
               xpath = '//*[contains(concat( " ", @class, " " ),
               concat( " ", "name", " " ))]') %>%
    html_text() %>%
    paste(., collapse = " ")

  articles_links$year[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(.,
               xpath = '//*[contains(concat( " ", @class, " " ),
               concat( " ", "name-section", " " ))]
               //*[contains(concat( " ", @class, " " ), concat( " ", "year", " " ))]') %>%
    html_text() %>%
    paste(., collapse = " ")

  articles_links$journal[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(., xpath = '//*[contains(concat( " ", @class, " " )
               , concat( " ", "pub-name", " " ))]') %>%
    html_text() %>%
    paste(., collapse = " ")

  articles_links$authors[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(., xpath = "/html/body/div/div/div/router-view/compose[1]/div/div/
               ma-entity-detail-info/compose/div/div/div[1]/
               ma-author-string-collection") %>%
    html_text() %>%
    paste(., collapse = " ")

  articles_links$tags[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(., xpath = "/html/body/div/div/div/router-view/compose[1]/
               div/div/ma-entity-detail-info/compose/
               div/div/div[1]/ma-tag-cloud/div") %>%
    html_text() %>%
    paste(., collapse = " ")
}

write_csv(articles_links, "microsoft_academic_clean.csv")
```

\newpage

# Session Information

```{r}
sessionInfo()
```
