---
title: |
       | Supplementary Materials for "The Effect of Legislature Size on Public Spending: A Meta-Analysis"
author: 
- "Huzeyfe Alptekin[^alptekin]"
- "Danilo Freire[^freire]"
- "Umberto Mignozzetti[^mignozzetti]"
- "Catarina Roman[^roman]"
date: June 13, 2020
fontfamily: libertine
fontawesome: yes
fontsize: 12pt
monospace-url: yes
spacing: double
papersize: a4paper
bibliography: references.bib
biblio-style: apalike
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    number_sections: yes
    toc: true
    keep_tex: no
    template: template.latex
---

\appendix

[^alptekin]: Research Associate, Contemporary Brazilian History Research and Documentation Center, School of Social Sciences, Getulio Vargas Foundation, Brazil, <huzeyfealptekin@gmail.com>.

[^freire]: Postdoctoral Research Associate, The Political Theory Project, Brown University, Providence, RI 02912, USA, <danilofreire@brown.edu>, <http://danilofreire.github.io>.

[^mignozzetti]: School of International Relations, Fundação Getulio Vargas, São Paulo, SP, Brazil and Wilf Family Department of Politics, NYU, NY, USA, <umberto.mig@nyu.edu>, <http://umbertomig.com>.

[^roman]: Research Associate, Department of International Relations, Getulio Vargas Foundation, Brazil, <catarinamroman@gmail.com>.

```{r, include=FALSE}
# Knitr options
knitr::opts_chunk$set(fig.pos = 'H') # holds figure position
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
## Starting
set.seed(732578) # From random.org

# Needed packages
pkgs <- c('tidyverse', 'meta', 'metafor', 
          'readxl', 'compareGroups',
          'knitr', 'gridGraphics', 'gridExtra',
          'ggpubr','kableExtra','magick')

# Install if not already installed
installIfNot <- function(x) {
  if(x %in% rownames(installed.packages()) == FALSE) 
    install.packages(x, dependencies = T, repos = "http://cran.us.r-project.org")
} 
lapply(pkgs, installIfNot)

# Load packs
lapply(pkgs, require, character.only = T)
rm(pkgs, installIfNot)

# Build plot function for forest plots
build_forest <- function(mod, capt, lsize = 22, ttl = NULL) {
  # Build dataset for plot
  mod2 <- tibble(
    TE = mod$TE,
    seTE = mod$seTE,
    studlab = mod$studlab,
    lower = mod$lower,
    upper = mod$upper,
    group = "A") %>%
    bind_rows(.,
              aux = tibble(
                TE = c(mod$TE.random, NA),
                seTE = c(mod$seTE.random, NA),
                studlab = c("Overall Effect", "Prediction Interval"),
                lower = c(mod$lower.random, mod$lower.predict),
                upper = c(mod$upper.random, mod$upper.predict),
                group = "B")) %>%
    group_by(studlab) %>%
    mutate(studlab2 = paste0(studlab, "_", 1:n())) %>%
    ungroup()
  
  # Graph limits
  limg <- max(abs(c(mod2$lower, mod2$upper)))
  
  # Build plot
  p <- mod2 %>%
    ggplot(aes(y = reorder(studlab2,TE), 
               x = TE, xmin = lower, xmax = upper)) +
    geom_point(aes(color = group)) +
    geom_errorbarh(aes(color = group), height = 0.1) +
    scale_color_manual(values = c("#000000", "#8b0000")) +
    scale_x_continuous(limits=c(-1.1*limg, 1.1*limg)) +
    scale_y_discrete(
      labels = function(x) str_replace(x, "_[0-9]*$", "")) + 
    geom_vline(xintercept=0, 
               color="#000000", linetype="dashed") +
    labs(x = "",
         y = "") + 
    facet_grid(group~., scales = "free", space = "free") + 
    labs(caption = capt,
         title = ttl) +
    theme_minimal() %+replace%
    theme(strip.text.y = element_blank(),
          legend.position = "none",
          axis.text.y = element_text(size = .8*lsize, 
                                     hjust = 1),
          axis.text.x = element_text(size = .6*lsize, 
                                     hjust = 1.1),
          plot.caption = element_text(size=lsize),
          plot.title.position = 'plot', 
          plot.title = element_text(hjust = 0.5, 
                                    face = 'bold',
                                    margin=margin(0,0,10,0)),
          panel.grid.major = element_blank())
  return(p)
}
```

# Search criteria

The first step in reviews is to gather a sample of records. This initial procedure is the foundation for the entire meta-analytical process: if the goal is to aggregate all the available data on a given topic, the primary pool must contain all of it. At the same time, the sample should be concise enough to optimise the work flow. Upon selecting the online databases, we attempted to do a "term" search, based on a set of words we scouted from the distributive politics literature we already knew. This search produced oversized databases, of which a large share was completely unrelated to our subject of investigation. The strategy we found to be the most thorough and productive was to select the records that cited Weingast, Shepsle and Johnsen's 1981 paper "The political economy of benefits and costs: A neoclassical approach to distributive politics". Although \href{https://scholar.google.com/}{Google Scholar} reports the article amounts to \href{https://scholar.google.com/scholar?um=1&ie=UTF-8&lr&cites=13117579863846712459}{2,180} citations\footnote{As of May 11\textsuperscript{th}, 2020.}, as of the 21\textsuperscript{st} of November 2019, our search resulted in a total of 2,664 records.

We webscraped the main databases in Social Sciences: \href{https://scholar.google.com/}{Google Scholar} (n = 1001); \href{https://academic.microsoft.com/home}{Microsoft Academic} (n = 927); and \href{https://www.scopus.com/}{Scopus} (n = 736). The R script we wrote extracted, to a CSV file, the title, abstract, authors, year, journal of publication, and database from which the record originated. We screened these results with an English language and Article restriction -- meaning, we excluded all records written in other languages and all that were not academic papers, such as book chapters, doctoral theses, etc. We set no restriction to unpublished articles.

# Article Selection

The selection process was conducted by two authors in three phases. In the first round, we excluded all titles that were obviously unrelated to our topic of investigation. For instance, we curiously found articles about automobile motors amidst our sample. We consider this a preliminary step, since we were not able to eliminate a large number of entries. Thus, we read all abstracts. We chose to maintain those that indicated either government expenditure or legislative structures were central matters. For instance, if the paper sought to identify variables that increased government size, it was maintained. Abstracts that indicated the paper discussed or estimated the impacts of representative institutions, elections, or chamber dynamics, for example, were also included. This allowed us to significantly reduce our sample to 376 records.

In the second phase, we assessed full-texts. To proceed, the paper should (i) conduct a quantitative analysis, (ii) report data on the number of legislators, and (iii) also on public expenditure. If the record was marked as positive for all three, it was maintained. Disagreements in this phase were discussed among the authors, and a third was consulted when needed.

The third phase consisted of filling out tables for each of the remaining 50 articles to systematically evaluate their eligibility. Since government spending and the number of parliamentaries assume the form of different variables, we extracted the coefficients that provided this information in all papers, indicating and defining which variables each author used. By observing what is most commonly used, we could decide which variables we would employ in our analysis. In this phase, we also collected information on whether or not the paper had been published, and if it explicitly discussed the \textit{law of 1/n}. Upon choosing the variables, we excluded the non-conforming studies, arriving at our final sample of 26 articles.

## Exclusion analysis

We selected the final pool of articles based on two criteria regarding their reported coefficients:

1. Matched treatment variable:
  + *N*: Number Legislators Lower House
  + *logN*: Log Number Legislators Lower House
  + *K*: Number Legislators Upper House
  
2. Matched outcome variable:
  + *ExpPC*: Expenditure Per Capita
  + *logExpPC*: Log Expenditure Per Capita
  + *PCTGDP*: Percent GDP Public Expenditure

## Flow Chart

We visually organised the flow of articles across eligibility phases through this diagram\footnote{According to the \href{www.prisma-statement.org/}{PRISMA} statement for reporting meta-analyses and systematic reviews}. The column to the right depicts the amount of articles excluded in each phase, and the one to the left shows the number of records evaluated.

\bigskip

```{tikz tikz-ex, echo=FALSE, cache=FALSE, eval=TRUE, engine.opts = list(template = "tikz2pdf.tex")}
\usetikzlibrary{shapes.arrows,arrows.meta,positioning,shapes.geometric}
  \begin{tikzpicture} [node distance = 2.7cm, xshift = 1.5]
    
  \footnotesize
  \linespread{1.0}    
    
  \node (ID) [stage, rotate = 90, yshift = 2cm, xshift = 2.5cm] {\normalsize{Identification}}; 
  
  \node (SC) [stage, below of = ID, rotate = 90] {\normalsize{Screening}};
      
  \node (EL) [stage, below of = SC, rotate = 90] {\normalsize{Eligibility}};
  
  \node (INC) [stage2, below of = EL, rotate = 90, xshift = -1.2cm] {\normalsize{Included}};
      
  \node (id) [phase, right of = ID, xshift = 1cm] {Records identified through webscraping  \\ \textbf{(n = 2664)}};
  
  \node (1st) [exc, right of = id, xshift = 3cm] {Records in languages other than English, book chapters, doctoral theses, and duplicates excluded \\ \textbf{(n = 1220)}};
  
  \node (screen) [phase, below of = id] {Records screened \\ \textbf{(n = 1445)}};
  
  \node (2nd) [exc, right of = screen, xshift = 3cm] {Records excluded after reading title and abstract \\ \textbf{(n = 1069)}};
  
  \node (elig) [phase, below of = screen] {Full-text articles assessed for Eligibility \\ \textbf{(n = 376)}};
  
  \node (3rd) [exc, right of = elig, xshift = 3cm] {Non-quantitative studies or records using unrelated variables excluded \\ \textbf{(n = 329)}};
  
  \node (inc_1) [phase, below of = elig] {Preliminary included articles \\ \textbf{(n = 47)}};
  
  \node (4th) [exc, right of = inc_1, xshift = 3cm] {Articles excluded during analysis due to nonconforming variables \\ \textbf{(n = 21)}};
  
\node (inc_2) [phase, below of = inc_1] {Included articles \\ \textbf{(n = 26)}};
  \draw [arrow] (id) -- (1st);
  \draw [arrow] (id) -- (screen);
  \draw [arrow] (screen) -- (2nd);
  \draw [arrow] (screen) -- (elig);
  \draw [arrow] (elig) -- (3rd);
  \draw [arrow] (elig) -- (inc_1);
  \draw [arrow] (inc_1) -- (4th);
  \draw [arrow] (inc_1) -- (inc_2);
  
 \end{tikzpicture}
```

# Meta-analysis dataset

The meta-analytic data is comprised of two datasets. The first dataset has the main coefficients that were reported in the paper. It includes only the most rigorous model from each paper, that is, those estimated with the largest $n$, most control variables, and fixed effects if the authors added them. If the article employed a regression discontinuity design, we chose the coefficient from the optimal bandwidth or from the intermediate one. This sample encompasses 36 estimates, as 10 articles analysed two dependent or independent variables of interest. Our second sample, in contrast, contains all the 126 effect sizes reported in the 26 papers. 

In the main text, we focus on the results for our restricted sample as we consider them more robust, but the findings are very similar when we use the extended set. Below is the data extraction process for all relevant coefficients in the selected articles. In the \@ref(meta-an) and \@ref(meta-reg) sections of this Appendix, you will find all tests performed in both reduced and full samples. 

```{r, echo=FALSE, include=FALSE}
load('../dataset/dataCoefs.RData')
```

# Descriptive statistics

In this section, we present the descriptive statistics for our meta-analytic sample. We focus in the following paper characteristics: study year, whether the paper has been published or not, the three dependent variables of interest, the three independent variables of interest, and a few statistics about the coefficients. We also add a descriptive statistics table, similar to the one in the main paper.

## Study Year

For study year, we have an average of `r round(mean(dat$year), 2)`, with standard deviation of `r round(sd(dat$year), 2)`. The oldest study included in the paper is dated from `r min(dat$year)`, while the most recent paper is dated from `r max(dat$year)`. Therefore, we cover `r max(dat$year)-min(dat$year)` years of tests of the 1/n hypothesis.

```{r, echo=FALSE, fig.width=7, fig.height=6, fig.cap="Study Year Frequencies"}
dat %>%
  select(id, year) %>%
  unique() %>%
  ggplot(aes(x = as.factor(year))) + 
    geom_bar(color = "black") + 
  labs(x = "",
       y = "") + 
  theme_bw()
```

## Frequency of Published Papers

We decided to report studies regardless of their publication status. From the `r length(unique(dat$id))` papers in the sample, `r as.numeric(table(unique(select(dat, id, published))$published)[1])` were published while `r as.numeric(table(unique(select(dat, id, published))$published)[2])` were not published.

```{r, echo=FALSE, fig.width=7, fig.height=6, fig.cap="Was the study published?"}
dat %>%
  select(id, published) %>%
  unique() %>%
  ggplot(aes(x = as.factor(published))) + 
    geom_bar(color = "black") + 
  labs(x = "Published study?",
       y = "") + 
  theme_bw()
```

## Electoral system

There are many differences in the papers relative to the research design. One remarkable difference is the application of the theory, that was build with majoritarian systems in mind, in non-majoritarian democracies. In our sample, `r as.numeric(table(unique(select(dat, id, elecsys2))$elecsys2)[1])` of the papers study *Majoritarian* systems while `r as.numeric(table(unique(select(dat, id, elecsys2))$elecsys2)[2])` study *Non-Majoritarian* electoral systems.\footnote{Note that the argument for working in a non-majoritarian system, we need to assume that despite the fact that politicians are able to campaign in every place in the district, the votes are geographycally concentrated. The concentration facilitates politicians to use pork-barrel project to captivate their electoral supporters.}

```{r, echo=FALSE, fig.width=7, fig.height=6, fig.cap="Electoral Systems"}
dat %>%
  select(id, elecsys2) %>%
  unique() %>%
  ggplot(aes(x=as.factor(elecsys2))) + 
    geom_bar(color = "black") + 
  labs(x = "Electoral Systems",
       y = "") + 
  theme_bw()
```

## Aggregation Level

The aggregation level is also an important characteristic of the empirical tests of the law of 1/n. The model was build to explain the dynamics of majoritarian countries, but the theory was tested in municipal, county, states, and country levels. In our sample, `r as.numeric(table(unique(select(dat, id, agglevel))$agglevel)[1])` studied *local* level (municipalities and counties), `r as.numeric(table(unique(select(dat, id, agglevel))$agglevel)[2])` studied *State* (or Provincial) levels, and `r as.numeric(table(unique(select(dat, id, agglevel))$agglevel)[3])` studied *Country* level data.

```{r, echo=FALSE, fig.width=7, fig.height=6, fig.cap="Sample Aggregate Level"}
dat %>%
  select(id, agglevel) %>%
  unique() %>%
  ggplot(aes(x=as.factor(agglevel))) + 
    geom_bar(color = "black") + 
  labs(x = "Sample Aggregate Level",
       y = "") + 
  theme_bw()
```

## Geographical Location

The geographical location also varies considerably in the sample. In our sampled papers, `r as.numeric(table(unique(select(dat, id, location2))$location2)[1])` studied a given country, while `r as.numeric(table(unique(select(dat, id, location2))$location2)[2])` used a cross-country design, with more than one country.

```{r, echo=FALSE, fig.width=7, fig.height=6, fig.cap="Geographical Location"}
dat %>%
  select(id, location2) %>%
  unique() %>%
  ggplot(aes(x=as.factor(location2))) + 
    geom_bar(color = "black") + 
  labs(x = "Geographical Location",
       y = "") + 
  theme_bw()
```

## Dependent variables

The outcome variables included in the paper were:

- `r as.numeric(table(unique(select(dat, id, depvar2))$depvar2)[1])` Per Capita Expenditure papers
- `r as.numeric(table(unique(select(dat, id, depvar2))$depvar2)[3])` Natural Log of Per Capita Expenditure papers
- `r as.numeric(table(unique(select(dat, id, depvar2))$depvar2)[2])` Expenditure as a Percentage of the GDP papers

```{r, echo=FALSE, fig.width=7, fig.height=6, fig.cap="Dependent variables across the law of 1/n studies"}
dat %>%
  select(id, depvar2) %>%
  unique() %>%
  mutate(depvar2 = factor(depvar2, 
                          labels = c("Per Capita Expenditure",
                                     "Percentage GDP Government Expenditure",
                                     "Log Per Capita Expenditure"))) %>%
  ggplot(aes(x = depvar2)) +
    geom_bar(color = "black") + 
  labs(x = "Dependent Variables",
       y = "") + 
  coord_flip() + 
  theme_bw()
```

## Independent variables

Most of papers in our meta-analytic sample study the number of legislators in the lower house (`r as.numeric(table(unique(select(dat, id, indepvar2))$indepvar2)[2])`). The second most frequent independent variable is the number of legislators in the upper house (`r as.numeric(table(unique(select(dat, id, indepvar2))$indepvar2)[1])`). Finally, the minority of papers study the Natural Log of the number of legislators in the lower house (`r as.numeric(table(unique(select(dat, id, indepvar2))$indepvar2)[3])`). Some papers had multiple coefficients, and thus the total number of coefficients is 36, while the number of papers is only 26.

```{r, echo=FALSE, fig.width=7, fig.height=6, fig.cap="Independent variables across the law of 1/n studies"}
dat %>%
  select(id, indepvar2) %>%
  unique() %>%
  mutate(indepvar2 = factor(indepvar2, labels = c('K (upper house legislators)',
                                                  'N (lower house legislators)',
                                                  'Log N'))) %>%
  ggplot(aes(x = indepvar2)) + 
    geom_bar(color = "black") + 
  labs(x = "Independent Variables",
       y = "") +
  coord_flip() +
  theme_bw() 
```

## Histogram of the Coefficients and the Standard Errors

The coefficients in the papers present a striking variability. In this section, we plot a histogram of the coefficients for all measurements included in the meta-analytic dataset.

```{r, echo=FALSE}
dat %>%
  ggplot(aes(x = coef)) +
  geom_histogram(bins = 15, color = "black") + 
  labs(x = "Coefficients") + 
  theme_bw()
dat %>%
  ggplot(aes(x = SE)) +
  geom_histogram(bins = 10, color = "black") + 
  labs(x = "Standard Errors") + 
  theme_bw()
```

## Sign Coefficients

One simple statistic that we can compute to access the law of 1/n is the frequency of positive and negative estimates. Below we plot the frequency for all the papers included in the meta-analytic dataset.

```{r, echo=FALSE, fig.width=7, fig.height=6, fig.cap="Coefficient Sign"}
dat %>%
  ggplot(aes(x=as.factor(scoef))) + 
  geom_bar(color = "black") + 
  labs(x = "Coefficient Sign",
       y = "") +
  theme_bw()
```

# Descriptive Statistics of Moderators

We chose a set of moderators that frequently appear in the literature and may help us interpret our results. We included them in our meta-regressions alongside an indicator for the type of independent variable used in the original study ($n$, log($n$), or $k$). The additional moderators are: 1) electoral system; 2) data aggregation level; 3) estimation method; 4) publication year; 5) paper publication in an academic journal. The table below presents descriptive statistics for these moderators in our selection of articles.

```{r, echo=F,warning=F,message=F}
fulldat$usemeta2 <- factor(fulldat$usemeta)
levels(fulldat$usemeta2) <- c('Other Coefficients', 'Main Coefficients')
aux <- select(fulldat, usemeta2, indepvar2, year, published, 
              elecsys2, method, agglevel, location2) %>%
  rename(`Independent Variables` = indepvar2,
         `Year` = year, 
         `Published work` = published, 
         `Electoral system` = elecsys2, 
         `Estimation method` = method, 
         `Sampling Aggregation Level` = agglevel, 
         `Sample Location` = location2)

export2md(descrTable(~.-usemeta2, aux, y = aux$usemeta2, 
                        show.p.overall = F, show.all = T),
          caption = "Descriptive Statistics of Moderators")
```

# Binomial Tests for Coefficient Signs

The law of 1/n poses we should have a positive influence of legislature size on expenditure. A general test of the theory could investigate whether the papers tend to find a higher frequency of positive coefficients. In statistical terms, consider a random variable representing the coefficient sign for the papers. As each sign of the paper is a Bernoulli trial, the aggregate for all papers follow a Binomial distribution, with parameters $n$ equals the number of papers, and $p$ the  chance of a positive sign. The law of 1/n can be reformulated as the chance of $p>0.5$, which facilitates the testing of the theory. The null hypothesis for such a test is that:

- $H_0$: the proportion of positive and negative signs are indistinguishable ($p=0.5$).

As we are taking an agnostic approach, we acknowledge that either the law of 1/n ($p>0.5$), or the reverse law of 1/n ($p<0.5$), could be true. In this case, the alternative hypothesis is $p\neq 0.5$. To perform this test, we run binomial tests in R, using the function `binom.test(.)`.

This test has at least two advantages. First, it is robust to the design of the paper. As papers select different types of journals, countries, samples, and other characteristics, this increases the heterogeneity. This test ignores the design discrepancies and focus on the overall effect. Second, this test has the advantage of be simple and straightfoward. It requires very few assumption and has a direct statistical formulation. The disadvantage is that we can extract more information with meta-regressions.

For the number of legislators in the lower house ($N$), the results follow below.

```{r, echo=FALSE}
aux <- filter(dat, indepvar2=='N')
aux2 <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p=0.5)
aux2
```

Under the null hypothesis of $p=0.5$, we find that `r as.numeric(table(aux$scoef)[2])` studies, out of `r sum(table(aux$scoef))`, had positive sign. The chance of a distribution with $p=0.5$ generate this sample is equal to p-value = `r round(as.numeric(aux2$p.value), 3)`. Therefore, we `r ifelse(as.numeric(aux2$p.value)<0.1, 'accept', 'reject')` the hypothesis that $p \neq 0.5$.

For the log of the number of legislators in the lower house ($\log(N)$), the results follow below.

```{r, echo=FALSE}
aux <- filter(dat, indepvar2=='logN')
aux2 <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p=0.5)
aux2
```

Under the null hypothesis of $p=0.5$, we find that `r as.numeric(table(aux$scoef)[2])` studies, out of `r sum(table(aux$scoef))`, had positive sign. The chance of a distribution with $p=0.5$ generate this sample is equal to p-value = `r round(as.numeric(aux2$p.value), 3)`. Therefore, we `r ifelse(as.numeric(aux2$p.value)<0.1, 'accept', 'reject')` the hypothesis that $p \neq 0.5$.

Finally, for the number of legislators in the upper house ($K$), the results follow below.

```{r, echo=FALSE}
aux <- filter(dat, indepvar2=='K')
aux2 <- binom.test(table(aux$scoef)[2], sum(table(aux$scoef)), p=0.5)
aux2
```

Under the null hypothesis of $p=0.5$, we find that `r as.numeric(table(aux$scoef)[2])` studies, out of `r sum(table(aux$scoef))`, had positive sign. The chance of a distribution with $p=0.5$ generate this sample is equal to p-value = `r round(as.numeric(aux2$p.value), 3)`. Therefore, we `r ifelse(as.numeric(aux2$p.value)<0.1, 'accept', 'reject')` the hypothesis that $p \neq 0.5$. This is the only test that presents evidence of an association between the legislature size and expenditure.

# Meta-analysis {#meta-an}

We combined the three independent ($N$, $\log(N)$, and $K$) with the levels of the three dependent variables (Expenditure Per Capita, Log of Expenditure Per Capita, Expenditure as a Percentage of the GDP). This formed a 3x3 possibility for our analysis.

## Per Capita Expenditure x N

```{r, echo=FALSE}
# Pooling effects analysis -- ExpPC x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'ExpPC')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=8, fig.height=4, fig.cap="Effect of lower houses size (N) on Per Capita Expenditure (ExpPC)",warning=FALSE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F}
f1 <- build_forest(mod, NULL, lsize = 15, ttl = 'Lower House Size\nand Expenditure per Capita')
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

\newpage

### Electoral system subgroup analysis

The law of 1/n was created for majoritarian systems. In the theoretical section below, we explain why the argument have potential issues when applied to non-majoritarian electoral systems. We estimated a subgroup analysis using a binary electoral system.

```{r, echo=FALSE, fig.width=8, fig.height=6, fig.cap="Subgroup Analysis of (N) x (ExpPC), controlling by electoral system",warning=FALSE}
mod <- update(mod, byvar = aux$elecsys2, print.byvar = F)

mod2 <- tibble(
  TE = mod$TE,
  seTE = mod$seTE,
  studlab = mod$studlab,
  lower = mod$lower,
  upper = mod$upper,
  group = "A") %>%
  bind_rows(.,
            aux = tibble(
              TE = c(mod$TE.random, NA),
              seTE = c(mod$seTE.random, NA),
              studlab = c("Overall Effect", "Prediction Interval"),
              lower = c(mod$lower.random, mod$lower.predict),
              upper = c(mod$upper.random, mod$upper.predict),
              group = "B")) %>%
  group_by(studlab) %>%
  mutate(studlab2 = paste0(studlab, "_", 1:n())) %>%
  ungroup()


f1b <- mod2 %>%
  ggplot(aes(y = reorder(studlab2,TE), x = TE, xmin = lower, xmax = upper)) +
  # Studies coefs
  geom_point(aes(color = group)) +
  # Error Bars
  geom_errorbarh(aes(color = group), height = 0.1) +
  # Colors
  scale_color_manual(values = c("#000000", "#8b0000")) + 
  # X-axis limit
  scale_x_continuous(limits=c(1.2*(min(mod2$lower)), 1.2*(max(mod2$upper)))) +
  # Y-axis names
  scale_y_discrete(labels = function(x) str_replace(x, "_[0-9]*$", "")) + 
  # Vertical dashed line
  geom_vline(xintercept=0, color="#000000", linetype="dashed") +
  # Labels
  labs(x = "",
       y = "") + 
  # Facet - Separating Studies from Overall Effect
  facet_grid(group~., scales = "free", space = "free") + 
  # Theme
  theme_minimal() %+replace%
  theme(strip.text.y = element_blank(),
        legend.position = "none",
        axis.text.y = element_text(size = 15, hjust = 1.1),
        axis.text.x = element_text(size = 15, hjust = 1.1)) 

f1b
```

Therefore, we can see that the hypothesis that majoritarian systems produce systematic positive effects was disproved. The majoritarian systems in the sample had a random effects model estimate of -0.25, while the random effects model in the non-majoritarian subgroup fitted a value of 0.08. Both are non-significant, but they reassure us that the absense of effect is not caused by pooling multiple types of electoral systems.

\newpage

## Per Capita Expenditure x Log of Lower House Size

There were no studies that had per capita expenditure in the dependent variable and log of lower house size in the treatment variable.

\newpage

## Per Capita Expenditure x Size of the Upper House

Now we are investigating the upper house size (K). In this model, we investigate the effect of upper house size on expenditure per capita (ExpPC).

```{r}
# Pooling effects analysis -- ExpPC x K
aux <- dat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'ExpPC')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=7, fig.height=4, fig.cap="Effect of upper house size (K) on the per capita government expenditure (ExpPC)",warning=FALSE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F}
f2 <- build_forest(mod, NULL, 15, ttl = 'Upper House Size\nand Expenditure Per Capita')
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

\newpage

## Log of Expenditure Per Capita x Size of the Lower House

This model estimates the Log of Per Capita Expenditure as the dependent variable, and the number of lower house legislators as the treatment variable.

```{r}
# Pooling effects analysis -- logExpPC x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'logExpPC')

mod <- metagen(
  coef, SE, data=aux, 
  studlab=paste(authoryear),
  comb.fixed = FALSE,
  comb.random = TRUE,
  method.tau = "REML",
  hakn = TRUE,
  prediction = TRUE,
  sm="SMD"
  )

mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=8, fig.height=3, fig.cap="Effect of lower houses size (N) on log of per capita expenditure (logExpPC)",warning=FALSE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F}
f3 <- build_forest(mod, NULL, 15, ttl = 'Lower House Size\nand Log Expenditure Per Capita')
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

\newpage

## Log of Expenditure Per Capita x Log of Lower House Size

In this specification, we study the log of per capita expenditure (logExpPC) as a function of the log of lower house size (logN).

```{r}
# Pooling effects analysis -- logExpPC x logN
aux <- dat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'logExpPC')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=8, fig.height=4, fig.cap="Effect of log lower houses size (logN) on the log of per capita government expenditure (logExpPC)",warning=FALSE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F}
f4  <- build_forest(mod, NULL, 15, ttl = 'Log of Lower House Size\nand Log of Expenditure Per Capita')
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`). **This model is significant at the 10\% confidence level.**
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

\newpage

## Log of Expenditure Per Capita x Size of Upper House

No studies related the log of per capita expenditure with the size of upper house (K).

## Expenditure as a Percentage of the GDP x Lower House Size

This model fits the random effects for the percentage of GDP as public expenditure as the main outcome, and the size of lower house as the main treatment variable.

```{r}
# Pooling effects analysis -- PCTGDP x N
aux <- dat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'PCTGDP')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=8, fig.height=3, fig.cap="Effect of lower houses size (N) on percentage of public expenditure GDP (PCTGDP)",warning=FALSE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F}
f5 <- build_forest(mod, NULL, 15, ttl = 'Lower House Size\nand Expenditure as Percentage of GDP')
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

\newpage
## Expenditure as a Percentage of the GDP x Log of Lower House Size

This meta-regression investigates the percentage of GDP as public expenditure as the dependent variable and the log lower house size (logN) as the treatment variable.

```{r}
# Pooling effects analysis -- PCTGDP x logN
aux <- dat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'PCTGDP')

mod <- metagen(
  coef, SE, data=aux, 
  studlab=paste(authoryear),
  comb.fixed = FALSE,
  comb.random = TRUE,
  method.tau = "REML",
  hakn = TRUE,
  prediction=TRUE,
  sm="SMD"
  )

mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=8, fig.height=4, fig.cap="Effect of log lower houses size (logN) on the GDP share of public expenditure (PCTGDP)",warning=FALSE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F}
f6 <- build_forest(mod, NULL, 15, ttl = 'Log Lower House Size\nand Expenditure as Percentage of GDP')
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

\newpage
## Expenditure as a Percentage of the GDP x Upper House Size

This model looks into the effect of upper house size (K) on the public expenditure share of the GDP (PCTGDP).

```{r}
# Pooling effects analysis -- PCTGDP x K
aux <- dat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'PCTGDP')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=8, fig.height=4, fig.cap="Effect of upper house size (K) on the public expenditure share of the GDP (PCTGDP)",warning=FALSE}
build_forest(mod, NULL)
```

```{r,include=F,warning=F}
f7 <- build_forest(mod, NULL, 15, ttl = 'Upper House Size\nand Expenditure as Percentage of GDP')
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

\newpage

```{r, echo=FALSE, fig.width=20, fig.height=5, warning=F}
f <- ggarrange(f1, f3, f5, 
               ggplot() + theme_void(), f4, f6, 
               f2, f7, ggplot() + theme_void(),
               ncol = 3, nrow = 3, 
               hjust = 0, align = 'hv')
ggsave("./plots/fig.pdf", plot = f, width = 35, height = 25, units = "cm")
```

\newpage
# Meta-Analysis (all coefficients) {#full-meta-an}

## ExpPC x N

```{r, echo=FALSE, warning=F}
# Pooling effects analysis -- ExpPC x N
aux <- fulldat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'ExpPC')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=12, fig.height=6, fig.cap="Effect of lower houses size (N) on Per Capita Expenditure (ExpPC)",warning=FALSE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

\newpage
### Electoral system subgroup analysis

The law of 1/n was created for majoritarian systems. In the theoretical section below, we explain why the argument have potential issues when applied to non-majoritarian electoral systems. We estimated a subgroup analysis using a binary electoral system.

```{r, echo=FALSE, fig.width=8, fig.height=6, fig.cap="Subgroup Analysis of (N) x (ExpPC), controlling by electoral system",warning=FALSE}
mod2 <- tibble(
  TE = mod$TE,
  seTE = mod$seTE,
  studlab = mod$studlab,
  lower = mod$lower,
  upper = mod$upper,
  group = "A") %>%
  bind_rows(.,
            aux = tibble(
              TE = c(mod$TE.random, NA),
              seTE = c(mod$seTE.random, NA),
              studlab = c("Overall Effect", "Prediction Interval"),
              lower = c(mod$lower.random, mod$lower.predict),
              upper = c(mod$upper.random, mod$upper.predict),
              group = "B")) %>%
  group_by(studlab) %>%
  mutate(studlab2 = paste0(studlab, "_", 1:n())) %>%
  ungroup()

f8b <- mod2 %>%
  ggplot(aes(y = reorder(studlab2,TE), x = TE, xmin = lower, xmax = upper)) +
  # Studies coefs
  geom_point(aes(color = group)) +
  # Error Bars
  geom_errorbarh(aes(color = group), height = 0.1) +
  # Colors
  scale_color_manual(values = c("#000000", "#8b0000")) + 
  # X-axis limit
  scale_x_continuous(limits=c(1.2*(min(mod2$lower)), 1.2*(max(mod2$upper)))) +
  # Y-axis names
  scale_y_discrete(labels = function(x) str_replace(x, "_[0-9]*$", "")) + 
  # Vertical dashed line
  geom_vline(xintercept=0, color="#000000", linetype="dashed") +
  # Labels
  labs(x = "",
       y = "") + 
  # Facet - Separating Studies from Overall Effect
  facet_grid(group~., scales = "free", space = "free") + 
  # Theme
  theme_minimal() %+replace%
  theme(strip.text.y = element_blank(),
        legend.position = "none",
        axis.text.y = element_text(size = 13, hjust = 1.1),
        axis.text.x = element_text(size = 15, hjust = 1.1)) 
f8b
```

Therefore, we can see that the hypothesis that majoritarian systems produce systematic positive effects was disproved. The majoritarian systems in the sample had a random effects model estimate of -0.25, while the random effects model in the non-majoritarian subgroup fitted a value of 0.08. Both are non-significant, but they reassure us that the absense of effect is not caused by pooling multiple types of electoral systems.

\newpage
## ExpPC x logN

There were no studies that had per capita expenditure in the dependent variable and log of lower house size in the treatment variable.

## ExpPC x K

Now we are investigating the upper house size (K). In this model, we investigate the effect of upper house size on expenditure per capita (ExpPC).

```{r, warning=F}
# Pooling effects analysis -- ExpPC x K
aux <- fulldat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'ExpPC')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=7, fig.height=4, fig.cap="Effect of upper house size (K) on the per capita government expenditure (ExpPC)",warning=FALSE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

\newpage
## logExpPC x N

This model estimates the Log of Per Capita Expenditure as the dependent variable, and the number of lower house legislators as the treatment variable.

```{r, warning=F}
# Pooling effects analysis -- logExpPC x N
aux <- fulldat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'logExpPC')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=8, fig.height=3, fig.cap="Effect of lower houses size (N) on log of per capita expenditure (logExpPC)",warning=FALSE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

\newpage
## logExpPC x logN

In this specification, we study the log of per capita expenditure (logExpPC) as a function of the log of lower house size (logN).

```{r, warning=F}
# Pooling effects analysis -- logExpPC x logN
aux <- fulldat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'logExpPC')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=8, fig.height=4, fig.cap="Effect of log lower houses size (logN) on the log of per capita government expenditure (logExpPC)",warning=FALSE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`). **This model is significant at the 10\% confidence level.**
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## logExpPC x K

No studies related the log of per capita expenditure with the size of upper house (K).

\newpage

## PCTGDP x N

This model fits the random effects for the percentage of GDP as public expenditure as the main outcome, and the size of lower house as the main treatment variable.

```{r, warning=F}
# Pooling effects analysis -- PCTGDP x N
aux <- fulldat %>%
  filter(indepvar2 == 'N',
         depvar2 == 'PCTGDP')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=8, fig.height=3, fig.cap="Effect of lower houses size (N) on percentage of public expenditure GDP (PCTGDP)",warning=FALSE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## PCTGDP x logN

This meta-regression investigates the percentage of GDP as public expenditure as the dependent variable and the log lower house size (logN) as the treatment variable.

```{r, warning=F}
# Pooling effects analysis -- PCTGDP x logN
aux <- fulldat %>%
  filter(indepvar2 == 'logN',
         depvar2 == 'PCTGDP')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=8, fig.height=4, fig.cap="Effect of log lower houses size (logN) on the GDP share of public expenditure (PCTGDP)",warning=FALSE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

## PCTGDP x K

This model looks into the effect of upper house size (K) on the public expenditure share of the GDP (PCTGDP).

```{r, warning=F}
# Pooling effects analysis -- PCTGDP x K
aux <- fulldat %>%
  filter(indepvar2 == 'K',
         depvar2 == 'PCTGDP')

mod <- metagen(coef, SE, data=aux, 
          studlab=paste(authoryear),
          comb.fixed = FALSE,
          comb.random = TRUE,
          method.tau = "REML",
          hakn = TRUE,
          prediction=TRUE,
          sm="SMD")
mod
```

And the forest plot:

```{r, echo=FALSE, fig.width=8, fig.height=4, fig.cap="Effect of upper house size (K) on the public expenditure share of the GDP (PCTGDP)",warning=FALSE}
build_forest(mod, NULL)
```

Highlights:

1. The results are highly heterogeneous: $I^2 = $ `r round(mod$I2*100, 2)`.
2. The Random effects modem SMD estimated is $g = $ `r round(mod$TE.random,2)` ($SE =$ `r round(mod$seTE.random,3)`).
3. The prediction interval ranges from `r round(mod$lower.predict,2)` to `r round(mod$upper.predict,2)`. Therefore, it `r ifelse(((mod$lower.predict)*(mod$upper.predict))>0,'does not emcompasses zero.','emcompasses zero.')`

# Meta-regressions {#meta-reg}

## Meta-regressions for Expenditure as a Percentage of the GDP

```{r, echo=F, warning=F}
mod <-  rma(yi = coef, 
              sei = SE, 
              data = dat, 
              method = "REML", 
              mods = ~indepvar2+year+published+elecsys2+method+agglevel+location2, 
              test = "knha",
            subset = dat$depvar2=='PCTGDP',
            slab = dat$authoryear)

mod1 <- tibble(
     ` ` = c("Intercept", "Indepvar: N", "Indepvar: logN", "Year", "Published: No",
          "Elecsys: Non-Majoritarian", "Method: Panel", "AggLevel: States", "Location: World"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ", 
              round(mod[["ci.ub"]], digits = 4), ")"),
  model = "PCTGDP"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 4)))
```

```{r, warning=F}
summary(mod)
```

As we have considerable heterogeneity in our sample, we run a permutation test to ensure the validity of our estimates. The results follow below.

```{r, echo=FALSE, warning=F}
mod <- permutest(mod, progbar = F)
mod

mod1_permu <- tibble(
     ` ` = c("Intercept", "Indepvar: N", "Indepvar: logN", "Year", "Published: No",
          "Elecsys: Non-Majoritarian", "Method: Panel", "AggLevel: States", "Location: World"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "PCTGDP - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3))) 
```

We have the following results for the meta-regressions of Expenditure Per Capita:

1. Compared with `K`, models with `N` and `logN` find significantly negative coefficients.
2. Year has null effect.
3. Unpublished papers tend to have higher coefficients than published papers.
4. Passing from `Majoritarian` to `Non-Majoritarian`, decreases significantly the effects found in our models.
5. In terms of the modeling, passing from `OLS` to `PANEL` increases the detected effects.
6. When passing from `Local` to `State` or `World` levels, it decreases the detected effect size.

Below we also run the meta-regressions adding all coefficients in the papers. The results follow below:

```{r, echo=F, warning=F}
mod <- rma(yi = coef, 
              sei = SE, 
              data = fulldat, 
              method = "REML", 
              mods = ~ indepvar2+year+published+elecsys2+method+agglevel+location2, 
              test = "knha",
            subset = fulldat$depvar2=='PCTGDP',
            slab = fulldat$authoryear)

mod2 <- tibble(
  ` ` = c("Intercept", "Indepvar: N", "Indepvar: logN", "Year", "Published: No",
          "Elecsys: Non-Majoritarian", "Method: Panel", "AggLevel: States", "Location: World"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "PCTGDP - All coefs"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3))) 
```

```{r, warning=F}
summary(mod)
```

```{r, echo=FALSE, warning=F}
mod <- permutest(mod, progbar = F)
mod 

mod2_permu <- tibble(
     ` ` = c("Intercept", "Indepvar: N", "Indepvar: logN", "Year", "Published: No",
          "Elecsys: Non-Majoritarian", "Method: Panel", "AggLevel: States", "Location: World"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "PCTGDP - All coefs - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

For all the coefficients, we have the following results:

1. Compared with `K`, models with `N` and `logN` tend to have significantly negative coefficients.
2. Year has a positive effect: the younger the publication, the higher the detected coefficient.
3. Unpublished papers tend to have higher coefficients than published papers.
4. Passing from `Majoritarian` to `Non-Majoritarian`, decreases significantly the effects found in our models.
5. In terms of the modeling, passing from `OLS` to `PANEL` increases the detected effects.
6. When passing from `Local` to `State` or `World` levels, it decreases the detected effect size.

## Meta-regressions for Expenditure Per Capita

```{r, echo=F, warning=F}
mod <-  rma(yi = coef, 
              sei = SE, 
              data = dat, 
              method = "REML", 
              mods = ~indepvar2+year+published+elecsys2+method+agglevel+location2, 
              test = "knha",
            subset = dat$depvar2=='ExpPC',
            slab = dat$authoryear)

mod3 <- tibble(
  ` ` = c("Intercept", "Indepvar: N", "Year", "Elecsys: Non-Majoritarian", "Method: Panel",
          "Method: IV", "AggLevel: States"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "ExpPC"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

```{r, warning=F}
summary(mod)
```

As we have considerable heterogeneity in our sample, we run a permutation test to ensure the validity of our estimates. The results follow below.

```{r, echo=FALSE, warning=F}
mod <- permutest(mod, progbar = F)
mod 

mod3_permu <- tibble(
  ` ` = c("Intercept", "Indepvar: N", "Year", "Elecsys: Non-Majoritarian", "Method: Panel",
          "Method: IV", "AggLevel: States"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "ExpPC - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3))) 
```

We have the following results for the meta-regressions of Expenditure Per Capita:

1. Compared with `K`, models with `N` tend to detect significantly smaller effects.
2. Year has null effect.
3. Passing the electoral rules from `Majoritarian` to `Non-Majoritarian`, increases significantly the per capita expenditure found in our models.
4. In terms of the modeling, passing from `OLS` to `PANEL` or `IV` increases the detected effects.
5. When passing from `Local` to `State` level, decreases the detected effects.

Below we also run the meta-regressions adding all coefficients in the papers. The results follow below:

```{r, echo=F, warning=F}
mod <- rma(yi = coef, 
              sei = SE, 
              data = fulldat, 
              method = "REML", 
              mods = ~ indepvar2+year+published+elecsys2+method+agglevel+location2, 
              test = "knha",
            subset = fulldat$depvar2=='ExpPC',
            slab = fulldat$authoryear)

mod4 <- tibble(
  ` ` = c("Intercept", "Indepvar: N", "Year", "Elecsys: Non-Majoritarian",
             "Method: Panel", "Method: IV" ,"AggLevel: States"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "ExpPC - All coefs"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

```{r, warning=F}
summary(mod)
```

```{r, echo=FALSE, warning=F}
mod <- permutest(mod, progbar = F)
mod

mod4_permu <- tibble(
  ` ` = c("Intercept", "Indepvar: N", "Year", "Elecsys: Non-Majoritarian",
             "Method: Panel", "Method: IV" ,"AggLevel: States"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "ExpPC - All coefs - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

With all coefficients, the results of the effect sizes on the Expenditure Per Capita Regressions are the following:

1. Compared with `K`, models with `N` tend to detect significantly smaller effects.
2. Year has now a positive effect on coefficient sizes.
3. Passing the electoral rules from `Majoritarian` to `Non-Majoritarian`, increases significantly the effects on per capita expenditure found in our models.
4. In terms of the modeling, passing from `OLS` to `PANEL` decreases the detected effects.
5. All other coeffients were not significant.

## Meta-regressions for the Log of Expenditure Per Capita

```{r, echo=F, warning=F}
mod <- rma(yi = coef, 
              sei = SE, 
              data = dat, 
              method = "REML", 
              mods = ~indepvar2+year+published+elecsys2+method+agglevel+location2, 
              test = "knha",
            subset = dat$depvar2=='logExpPC',
            slab = dat$authoryear)

mod5 <- tibble(
   ` ` = c("Intercept", "Indepvar: N", "Year", "Published: No",
             "Method: Panel", "AggLevel: States"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "logExpPC"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3))) 
```

```{r, warning=F}
summary(mod)
```

As we have considerable heterogeneity in our sample, we run a permutation test to ensure the validity of our estimates. The results follow below.

```{r, echo=FALSE, warning=F}
mod <- permutest(mod, progbar = F)
mod

mod5_permu <- tibble(
  ` ` = c("Intercept", "Indepvar: N", "Year", "Published: No",
             "Method: Panel", "AggLevel: States"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4 ), ")"),
  model = "logExpPC - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3))) 

mod5_permu %>%
  select(-model) %>%
  kable(booktabs = T,align = "c",linesep ='') %>%
  kable_styling(c("striped","bordered","scale_down"), position = "center")
```

We have the following results for the meta-regressions of Log of Expenditure Per Capita:

1. Unpublished papers report a significantly higher coefficient.
2. In terms of the modeling, passing from `OLS` to `PANEL` increases the detected effects.
3. All other coefficients remained insignificant.

Below we also run the meta-regressions adding all coefficients in the papers. The results follow below:

```{r, echo=F, warning=F}
mod <- rma(yi = coef, 
              sei = SE, 
              data = fulldat, 
              method = "REML", 
              mods = ~ indepvar2+year+published+elecsys2+method+agglevel+location2, 
              test = "knha",
            subset = fulldat$depvar2=='logExpPC',
            slab = fulldat$authoryear)

mod6 <- tibble(
  ` ` = c("Intercept", "Indepvar: N", "Year", "Published: No",
             "Method: Panel", "Method: RDD", "AggLevel: States"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4), ")"),
  model = "logExpPC - All coefs"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3)))
```

```{r, warning=F}
summary(mod)
```

```{r, echo=FALSE, warning=F}
mod <- permutest(mod, progbar = F)

mod6_permu <- tibble(
  ` ` = c("Intercept", "Indepvar: N", "Year", "Published: No",
             "Method: Panel", "Method: RDD", "AggLevel: States"),
  Estimate = mod[["beta"]],
  SE = mod[["se"]],
  `T` = mod[["zval"]],
  `P-Value` = mod[["pval"]],
  CI = paste0("(", round(mod[["ci.lb"]], digits = 4), " ; ",
              round(mod[["ci.ub"]], digits = 4), ")"),
  model = "logExpPC - All coefs - Permutation"
) %>%
  mutate_if(is.numeric, list(~round(., digits = 3))) 
```

With all coefficients, the results of the effect sizes on the Log of Expenditure Per Capita Regressions are the following:

1. In terms of the modeling, passing from `OLS` to `PANEL` or `RDD` decreases the detected effects.
2. All other coefficients remained insignificant.

```{r, echo=F, warning=F, error=F, message=F}
coefs <- tibble(
  ` ` = c("Intercept", "Indepvar: N","Indepvar: logN", "Year", "Published: No", "Elecsys: Non-Majoritarian",
    "Method: Panel", "Method: IV", "Method: RDD", "AggLevel: States", "Location: World"))

aux = list(mod3, mod5, mod1) %>%
  map(~{
    left_join(coefs, .x) %>%
      mutate(model = ifelse(is.na(model), model[1], model)) 
  }) %>%
  reduce(bind_cols) %>%
  mutate(
         order = ifelse(` ` == "Intercept", 1, NA),
         order = ifelse(` ` == "Indepvar: N", 2, order),
         order = ifelse(` ` == "Indepvar: logN", 3, order),
         order = ifelse(` ` == "Year", 4, order),
         order = ifelse(` ` == "Published: No", 5, order),
         order = ifelse(` ` == "Elecsys: Non-Majoritarian", 6, order),
         order = ifelse(` ` == "Method: Panel", 7, order),
         order = ifelse(` ` == "Method: IV", 8, order),
         order = ifelse(` ` == "Method: RDD", 9, order),
         order = ifelse(` ` == "AggLevel: States", 10, order),
         order = ifelse(` ` == "Location: World", 11, order)) %>%
  filter(` ` != "Method: RDD") %>%
  arrange(order) %>%
  mutate_at(vars(contains("Value")), list(
    ~(ifelse(is.na(.), " ", ifelse(. < 0.001, "***",
                       ifelse(. < 0.01, "**",
                              ifelse(. < 0.05, "*", 
                                     ifelse(. >= 0.05, " ", 
                                            ifelse(is.na(.), " ", .))))))))) %>%
  mutate_at(vars(contains("Estimate") | contains("SE")),
            list(~(ifelse(is.na(.), " ", .)))) %>%
  select(-` 1`, -` 2`, -contains("model"), -order) %>%
  mutate(mod = "Base") %>%
  select(mod, everything())

aux2 = list(mod4, mod6, mod2) %>%
  map(~{
    left_join(coefs, .x) %>%
      mutate(model = ifelse(is.na(model), model[1], model)) 
  }) %>%
  reduce(bind_cols) %>%
  mutate(
         order = ifelse(` ` == "Intercept", 1, NA),
         order = ifelse(` ` == "Indepvar: N", 2, order),
         order = ifelse(` ` == "Indepvar: logN", 3, order),
         order = ifelse(` ` == "Year", 4, order),
         order = ifelse(` ` == "Published: No", 5, order),
         order = ifelse(` ` == "Elecsys: Non-Majoritarian", 6, order),
         order = ifelse(` ` == "Method: Panel", 7, order),
         order = ifelse(` ` == "Method: IV", 8, order),
         order = ifelse(` ` == "Method: RDD", 9, order),
         order = ifelse(` ` == "AggLevel: States", 10, order),
         order = ifelse(` ` == "Location: World", 11, order)) %>%
  arrange(order) %>%
  mutate_at(vars(contains("Value")), list(
    ~(ifelse(is.na(.), " ", ifelse(. < 0.001, "***",
                       ifelse(. < 0.01, "**",
                              ifelse(. < 0.05, "*", 
                                     ifelse(. >= 0.05, " ", 
                                            ifelse(is.na(.), " ", .))))))))) %>%
  mutate_at(vars(contains("Estimate") | contains("SE")),
            list(~ifelse(is.na(.), " ", .))) %>%
  select(-` 1`, -` 2`, -contains("model"), -order) %>%
  mutate(mod = "All Coefs") %>%
  select(mod, everything())

aux <- bind_rows(aux, aux2) %>%
  select(-contains("CI"),-`T`,-T1,-T2)
```

\blandscape

# Summary of Results

```{r, echo=F, warning=F,error=F,message=F,asis=T}
kable(aux, 
      booktabs = T,
      longtable = F,
      align = "c",
      linesep ='',
      col.names = c(
        " ",
        " ",
        "Estimate",
        "SE",
        "P-Value",
        #
        "Estimate",
        "SE",
        "Signif",
        #
        "Estimate",
        "SE",
        "Signif"
      )) %>% 
  collapse_rows(
    1:2,
    row_group_label_position ='stack'
    ) %>%
  add_header_above(c(" ", " ","ExpPC" = 3, "logExpPC" = 3, "PCTGDP" = 3)) %>%
  kable_styling(
    c("striped",
      "bordered", 
      "scale_down",
      "repeat_header"
      ),
    position = "center",
    latex_options = c("repeat_header")) %>%
  footnote(general = "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1")

```
\elandscape

```{r, echo=F, warning=F,error=F,message=F}
coefs <- tibble(
  ` ` = c("Intercept", "Indepvar: N","Indepvar: logN", "Year", "Published: No", "Elecsys: Non-Majoritarian",
    "Method: Panel", "Method: IV", "Method: RDD", "AggLevel: States", "Location: World")
)

aux = list(mod3_permu, mod5_permu, mod1_permu) %>%
  map(~{
    left_join(coefs, .x) %>%
      mutate(model = ifelse(is.na(model), model[1], model)) 
  }) %>%
  reduce(bind_cols) %>%
  mutate(
         order = ifelse(` ` == "Intercept", 1, NA),
         order = ifelse(` ` == "Indepvar: N", 2, order),
         order = ifelse(` ` == "Indepvar: logN", 3, order),
         order = ifelse(` ` == "Year", 4, order),
         order = ifelse(` ` == "Published: No", 5, order),
         order = ifelse(` ` == "Elecsys: Non-Majoritarian", 6, order),
         order = ifelse(` ` == "Method: Panel", 7, order),
         order = ifelse(` ` == "Method: IV", 8, order),
         order = ifelse(` ` == "Method: RDD", 9, order),
         order = ifelse(` ` == "AggLevel: States", 10, order),
         order = ifelse(` ` == "Location: World", 11, order)) %>%
  arrange(order) %>%
  filter(` ` != "Method: RDD") %>%
  mutate_at(vars(contains("Value")), list(
    ~(ifelse(is.na(.), " ", ifelse(. < 0.001, "***",
                       ifelse(. < 0.01, "**",
                              ifelse(. < 0.05, "*", 
                                     ifelse(. >= 0.05, " ", 
                                            ifelse(is.na(.), " ", .))))))))) %>%
  mutate_at(vars(contains("Estimate") | contains("SE")),
            list(~ifelse(is.na(.), " ", .))) %>%
  select(-` 1`, -` 2`, -contains("model"), -order) %>%
  mutate(mod = "Base") %>%
  select(mod, everything())

aux2 = list(mod4_permu, mod6_permu, mod2_permu) %>%
  map(~{
    left_join(coefs, .x) %>%
      mutate(model = ifelse(is.na(model), model[1], model)) 
  }) %>%
  reduce(bind_cols) %>%
  mutate(order = ifelse(` ` == "Intercept", 1, NA),
         order = ifelse(` ` == "Indepvar: N", 2, order),
         order = ifelse(` ` == "Indepvar: logN", 3, order),
         order = ifelse(` ` == "Year", 4, order),
         order = ifelse(` ` == "Published: No", 5, order),
         order = ifelse(` ` == "Elecsys: Non-Majoritarian", 6, order),
         order = ifelse(` ` == "Method: Panel", 7, order),
         order = ifelse(` ` == "Method: IV", 8, order),
         order = ifelse(` ` == "Method: RDD", 9, order),
         order = ifelse(` ` == "AggLevel: States", 10, order),
         order = ifelse(` ` == "Location: World", 11, order)) %>%
  arrange(order) %>%
  mutate_at(vars(contains("Value")), list(
    ~(ifelse(is.na(.), " ", ifelse(. < 0.001, "***",
                       ifelse(. < 0.01, "**",
                              ifelse(. < 0.05, "*", 
                                     ifelse(. >= 0.05, " ", 
                                            ifelse(is.na(.), " ", .))))))))) %>%
  mutate_at(vars(contains("Estimate") | contains("SE")),
            list(~ifelse(is.na(.), " ", .))) %>%
  select(-` 1`, -` 2`, -contains("model"), -order) %>%
  mutate(mod = "All Coefs") %>%
  select(mod, everything())

aux <- bind_rows(aux, aux2) %>%
  select(-contains("CI"),-`T`,-T1,-T2)
```

\blandscape

# Summary of Results (Permutation)
```{r, echo=F, warning=F,error=F,message=F,asis=T}
kable(aux, 
      booktabs = T,
      longtable = F,
      align = "c",
      linesep ='',
      col.names = c(
        " ",
        " ",
        "Estimate",
        "SE",
        "Signif",
        #
        "Estimate",
        "SE",
        "Signif",
        #
        "Estimate",
        "SE",
        "Signif"
      )) %>% 
  collapse_rows(
    1:2,
    row_group_label_position ='stack'
    ) %>%
  add_header_above(c(" ", " ","ExpPC" = 3, "logExpPC" = 3, "PCTGDP" = 3)) %>%
  kable_styling(
    c("striped",
      "bordered", 
      "scale_down",
      "repeat_header"
      ),
    position = "center",
    latex_options = c("repeat_header")) %>%
  footnote(general = "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1")
```
\elandscape
\newpage

# The theory behind the Meta Analysis

There are two main estimators for conducting meta analysis: fixed effects and random effects models. The fixed effects model assumes that there is one true effect in reality, and that all estimates are an attempt to uncover this true effect. The random effects model, on the other hand, assumes that there are a distribution of true effects, that vary based on sample and tests characteristics.

In this paper, we use the random effects model. The empirical papers testing the law of 1/n are very diverse. We tried to capture some of this diversity by considering the main dependent and independent variables separately, but they have at least three other important sources of dispersion:

1. **Subjects**: Counties, Municipalities, States, Provinces, Countries.
2. **Electoral systems**: Majoritarian, PR, Mixed.
3. **Modeling strategies**: Panel data, Standard OLS, IV, RDD.

These sources of heterogeneity have two implications. First, it makes our estimates very disperse. The heterogeneity tests are all but one significant. When the sample sizes are large enough, we removed more heterogeneous studies, but we still had considerable dispersion in our estimates. Second, the amount of heterogeneity makes fixed effects estimates unrealistic and bised. Thus, we opt for random effects model.

Let each study having an effect of $T_i$. In a random effects model, we can decompose this effect in two components, the true effect that the study with the same specifications as $i$ come from, $\theta_i$, and a within-study error $\varepsilon_i$:

\[
T_i \ = \ \theta_i + \varepsilon_i
\]

And the random effects model assumes that the $\theta_i$ varies from study to study, having a true parameter $\mu$, plus a between-study error, $\xi_i$:

\[
T_i \ = \ \mu + \xi_i + \varepsilon_i
\]

And the random effects model estimates the parameter $\mu$, under the challenge of estimating both the within-and-between-study sampling errors.

In all empirical estimates, we use the package `meta`, and the package `dmetar`, described in (Doing Meta-Analysis with R)[https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/random.html]. To empirically implement the random effects model, we need to choose a method to estimate the true effect size variance, $\tau^2$, which in our formulation, represents the variance of $\xi_i$. We selected the **Restricted Maximum Likelihood Estimator**, as the literature regards it as more precise when we have continuous measures, such as we have on our data (link)[https://www.ncbi.nlm.nih.gov/pubmed/26332144].

# Robustness: Full model meta-regressions combined {#full-meta-reg}

In this section, we aggregate all the coefficients and run a multivariate meta-regression, controlling by:

1. The type of the dependent variable in the study (expenditure per capita, log of the expenditure per capita, and share of government expenditure in the GDP)
2. The type of the independent variable in the stydy (N, K, log of N);
3. The electoral system (Majoritarian, Proportional Representation, and Mixed).

The results follow below, and show null effect for all variables, including the intercept.

```{r, echo=F, warning=F}
mod <-  rma(yi = coef, 
              sei = SE, 
              data = dat, 
              method = "REML", 
              mods = ~ depvar2+indepvar2+year+published+elecsys2+method+agglevel+location2, 
              test = "knha")
```

```{r}
summary(mod)
```

As we have considerable heterogeneity in our sample, we run a permutation test to ensure the validity of our estimates. The results follow below.

```{r, echo=FALSE}
permutest(mod, progbar = F)
```

In the main text, we selected the coefficients based on the regressions that had most observations and that presented a full model (with fixed effects or intermediate bandwidth in RDD). Below we also run the meta-regressions adding all coefficients in the papers. The results follow below:

```{r, echo=F, warning=F}
mod <- rma(yi = coef, 
              sei = SE, 
              data = fulldat, 
              method = "REML", 
              mods = ~ depvar2+indepvar2+year+published+elecsys2+method+agglevel+location2, 
              test = "knha")
```

```{r}
summary(mod)
```

```{r}
permutest(mod, progbar = F)
```

# Auxiliary functions

## Graph functions code

This function is for building a forest plot using `ggplot2` from meta analysis dataset.

```{r, eval = FALSE}
# Build plot function for forest plots
build_forest <- function(mod, capt, lsize = 22, ttl = NULL) {
  # Build dataset for plot
  mod2 <- tibble(
    TE = mod$TE,
    seTE = mod$seTE,
    studlab = mod$studlab,
    lower = mod$lower,
    upper = mod$upper,
    group = "A") %>%
    bind_rows(.,
              aux = tibble(
                TE = c(mod$TE.random, NA),
                seTE = c(mod$seTE.random, NA),
                studlab = c("Overall Effect", "Prediction Interval"),
                lower = c(mod$lower.random, mod$lower.predict),
                upper = c(mod$upper.random, mod$upper.predict),
                group = "B")) %>%
    group_by(studlab) %>%
    mutate(studlab2 = paste0(studlab, "_", 1:n())) %>%
    ungroup()
  
  # Graph limits
  limg <- max(abs(c(mod2$lower, mod2$upper)))
  
  # Build plot
  p <- mod2 %>%
    ggplot(aes(y = reorder(studlab2,TE), 
               x = TE, xmin = lower, xmax = upper)) +
    geom_point(aes(color = group)) +
    geom_errorbarh(aes(color = group), height = 0.1) +
    scale_color_manual(values = c("#000000", "#8b0000")) +
    scale_x_continuous(limits=c(-1.1*limg, 1.1*limg)) +
    scale_y_discrete(
      labels = function(x) str_replace(x, "_[0-9]*$", "")) + 
    geom_vline(xintercept=0, 
               color="#000000", linetype="dashed") +
    labs(x = "",
         y = "") + 
    facet_grid(group~., scales = "free", space = "free") + 
    labs(caption = capt,
         title = ttl) +
    theme_minimal() %+replace%
    theme(strip.text.y = element_blank(),
          legend.position = "none",
          axis.text.y = element_text(size = .8*lsize, 
                                     hjust = 1),
          axis.text.x = element_text(size = .6*lsize, 
                                     hjust = 1.1),
          plot.caption = element_text(size=lsize),
          plot.title.position = 'plot', 
          plot.title = element_text(hjust = 0.5, 
                                    face = 'bold',
                                    margin=margin(0,0,10,0)),
          panel.grid.major = element_blank())
  return(p)
}
```

## Webscraping code

```{r, eval = FALSE}
#### PACKAGES CONFIGURATION ####

# Needed packages
pkgs <- c('tidyverse', 'rvest', 'RSelenium')

# Install if not already installed
installIfNot <- function(x) {
  if(x %in% rownames(installed.packages()) == FALSE) 
    install.packages(x, dependencies = T, repos = "http://cran.us.r-project.org")
} 
lapply(pkgs, installIfNot)

# Load packs
lapply(pkgs, require, character.only = T)
rm(pkgs, installIfNot)

#### SETTING UP SELENIUM ####

# Alternative 1: Setting up Selenium (head)
rsD <- rsDriver(port = 1114L, browser = c("firefox")) 
remDr <- rsD$client
remDr$open()

#### Google scholar ####

# site: https://scholar.google.com
remDr$navigate("https://scholar.google.com/
               scholar?cites=13117579863846712459&as_sdt=2005&sciodt=0,5")

articles_weingast <- tibble(
  value = NA,
  term = NA,
  page = NA
)

k <- 0

for (j in 1:213) { # we had to manually choose the number of pages here; Y.M.M.V.

  Sys.sleep(rpois(1, 5))

  # Getting articles basic information
  k <- k + 1

  webElem <- remDr$findElement("css", "body")


  title <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(
      xpath = '//*[contains(concat( " ", @class, " " ),
      concat( " ", "gs_rt", " " ))]'
      ) %>%
    html_text() %>%
    enframe(name = NULL) %>%
    rename("title" = "value") %>%
    mutate(page = k)

  articles_partial <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "gs_a", " " ))]') %>%
    html_text() %>%
    enframe(name = NULL) %>%
    bind_rows(
      tibble(
        value = "delete",
        term = NA,
        page = NA
      ),
      .
    ) %>%
    bind_cols(., title)


  # Binding articles
  articles_weingast <- bind_rows(articles_weingast, articles_partial)

  # Changing Pages
  next_button <- remDr$findElement(using = "xpath", "/html/body/div/div[11]/div[2]/div[2]/div[3]/
                                   div[2]/center/table/tbody/tr/td[12]/a/b")
  next_button$clickElement()
  # Deleting cookies
  remDr$deleteAllCookies()
}

write_csv(articles_weingast, "scholar_weingast_raw.csv")

articles_weingast <- articles_weingast %>%
  select(-term, -page) %>%
  filter(value != "delete") %>%
  slice(2:nrow(.)) %>%
  filter(!grepl("books.google.com", value)) %>%
  filter(!grepl("BOOK", title)) %>%
  separate(., value, into = c("author", "value"),
           sep = " -", remove = T, extra = "merge", fill = "right") %>%
  separate(., value, into = c("journal", "year"),
           sep = ",", remove = T, extra = "merge", fill = "right") %>%
  mutate(
    year_2 = ifelse(is.na(year), journal, year),
    journal = ifelse(is.na(year), NA, journal),
    year = year_2
  ) %>%
  select(-year_2) %>%
  separate(., year, into = c("year", "site"),
           sep = "-", remove = T, extra = "merge", fill = "right") %>%
  mutate(
    year = gsub("[^0-9 ]", "", value),
    year = gsub("^[0-9]{5,}", "", year),
    year = gsub("^ {1,}", "", year)
  ) %>%
  separate(., year, into = c("year", "junk"),
           sep = " ", remove = T, extra = "merge", fill = "right") %>%
  separate(., value, into = c("journal", "value"),
           sep = "-", remove = T, extra = "merge", fill = "right") %>%
  mutate(
    journal_untidy = year,
    year = gsub("[^0-9 ]", "", year)
  )

articles <- articles %>%
  na.omit() %>%
  distinct(., value, .keep_all = T)

write_csv(articles, "google_scholar_clean.csv")

#### SCOPUS ####

# url: https://www.scopus.com/home.uri

# Scraping Scopus requires a bit more manual labor.
# You can login on scopus through your university/institution 
# and download the metadata of the article(s) you 
# want directly from there.
# All we need to do after that is scrape the information of
# every link from the .csv file downloaded previously

scopus <- read_csv("scopus.csv")

scopus <- scopus %>%
  mutate(article = map_chr(Link, ~ {
    remDr$navigate(.x)
    read_html(remDr$getPageSource()[[1]]) %>%
      html_nodes(xpath = '//*[(@id = "abstractSection")]//p') %>%
      html_text() %>%
      paste(., collapse = "\r\n")
  })) %>%
  mutate(
    article = gsub(
      '\r\n\nUse this section.*Topics\n\n\n"',
      "",
      article
    ),
    article = gsub(
      "Topics are unique.*onwards.",
      "",
      article
    ),
    article = gsub(
      "Use this section.*documents.",
      "",
      article
    ),
    article = gsub(
      "Learn more about these Topics",
      "",
      article
    ),
    article = gsub(
      ". 20.*, Springer Science\\+Business Media, LLC, part of Springer Nature.",
      "",
      article
    ),
    article = gsub("\r", "", article),
    article = gsub("\n", "", article),
    article = gsub(" {2,}", " ", article),
    article = gsub(" {3,}", "", article)
  )

write_csv(scopus, "scopus_clean.csv")

#### Microsoft Academic ####

# url: https://academic.microsoft.com/home
articles <- list()
k <- 0
remDr$navigate("https://academic.microsoft.com/paper/
               2076316673/citedby/search?q=The%20Political%
               20Economy%20of%20Benefits%20and%20Costs%3A%20A%
               20Neoclassical%20Approach%20to
               %20Distributive%20Politics&qe=RId%253D2076316673&f=&orderBy=0")


# 1) Getting hyperlinks from articles
for (j in 1:100) {
  k <- k + 1
  print(k)

  # Navigating Website

  Sys.sleep(rpois(2, 5))

  # Getting articles' links
  articles[[k]] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(xpath = "//a") %>%
    html_attr("href") %>%
    enframe(name = NULL) %>%
    filter(
      grepl("paper/", value),
      !grepl("citedby", value)
    ) %>%
    mutate(value = paste0("https://academic.microsoft.com/", value))

  # Changing Page
  next_page_others <- remDr$findElement(using = "xpath", "/html/body/div/div/div/router-view/router-view/                                        ma-edp-serp/div/div[2]/div/
  compose/div/div[2]/ma-pager/div/i[2]")
  next_page_others$clickElement()
}


articles <- articles %>%
  reduce(bind_rows) %>%
  distinct(value, .keep_all = T)

# 2) Navigating through articles and scraping them

articles_links <- articles %>%
  mutate(
    abstract = NA,
    title = NA,
    year = NA,
    journal = NA,
    authors = NA,
    tags = NA
  )

for (i in 1:nrow(articles_links)) {
  remDr$navigate(articles_links$value[i])
  Sys.sleep(rpois(1, 4))

  articles_links$abstract[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(., xpath = "//html/body/div/div/div/router-view/compose[1]/
               div/div/ma-entity-detail-info/compose/div/div/div[1]/p") %>%
    html_text() %>%
    paste(., collapse = " ")

  articles_links$title[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(.,
               xpath = '//*[contains(concat( " ", @class, " " ),
               concat( " ", "name", " " ))]') %>%
    html_text() %>%
    paste(., collapse = " ")

  articles_links$year[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(., 
               xpath = '//*[contains(concat( " ", @class, " " ),
               concat( " ", "name-section", " " ))]
               //*[contains(concat( " ", @class, " " ), concat( " ", "year", " " ))]') %>%
    html_text() %>%
    paste(., collapse = " ")

  articles_links$journal[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(., xpath = '//*[contains(concat( " ", @class, " " )
               , concat( " ", "pub-name", " " ))]') %>%
    html_text() %>%
    paste(., collapse = " ")

  articles_links$authors[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(., xpath = "/html/body/div/div/div/router-view/compose[1]/div/div/
               ma-entity-detail-info/compose/div/div/div[1]/
               ma-author-string-collection") %>%
    html_text() %>%
    paste(., collapse = " ")

  articles_links$tags[i] <- read_html(remDr$getPageSource()[[1]]) %>%
    html_nodes(., xpath = "/html/body/div/div/div/router-view/compose[1]/
               div/div/ma-entity-detail-info/compose/
               div/div/div[1]/ma-tag-cloud/div") %>%
    html_text() %>%
    paste(., collapse = " ")
}

write_csv(articles_links, "microsoft_academic_clean.csv")
```

# Software Version for this Appendix

```{r}
sessionInfo()
```